{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscope: feature engineering for i2b2 data set\\nlast modified: 9/4/19\\nauthor: andrew malinow\\nto-do\\n-fix blood pressure\\n-finish vitals (temp, respitory)\\n-have Jason create new columns for entities\\n-Jason to double-check/revise as needed LOS calculation\\n- word2vec on large text columns\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "scope: feature engineering for i2b2 data set\n",
    "last modified: 11-20-19\n",
    "author: andrew malinow\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |################################| 1.5MB 4.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /conda/envs/rapids/lib/python3.6/site-packages (from nltk) (1.12.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "install dependencies\n",
    "\"\"\"\n",
    "#!pip install pyforest\n",
    "#!pip install -U spacy[cuda]\n",
    "#!pip install -U cupy\n",
    "#!pip install -U chainer\n",
    "#!pip uninstall cupy -y\n",
    "#!pip install cupy --no-cache-dir\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not using GPU\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.require_gpu=False\n",
    "if (spacy.require_gpu==True):\n",
    "    print ('using gpu')\n",
    "else:\n",
    "    print ('not using GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu\n"
     ]
    }
   ],
   "source": [
    "spacy.require_gpu=True\n",
    "if (spacy.require_gpu==True):\n",
    "    print ('using gpu')\n",
    "else:\n",
    "    print ('not using GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "from pyforest import *\n",
    "#import pickle\n",
    "#import gensim\n",
    "import cudf\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "#from gensim.models import FastText\n",
    "#import pandas as pd\n",
    "#import cudf\n",
    "#import os\n",
    "#import re\n",
    "import time\n",
    "#import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "#from datetime import datetime\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/conda/envs/rapids/nltk_data'\n    - '/conda/envs/rapids/share/nltk_data'\n    - '/conda/envs/rapids/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/conda/envs/rapids/nltk_data'\n    - '/conda/envs/rapids/share/nltk_data'\n    - '/conda/envs/rapids/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-458c0e039108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEnglish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0men_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/conda/envs/rapids/nltk_data'\n    - '/conda/envs/rapids/share/nltk_data'\n    - '/conda/envs/rapids/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "global variables\n",
    "\"\"\"\n",
    "parser=English()\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read in data\n",
    "\"\"\"\n",
    "\n",
    "data=pd.read_csv(\"/rapids/notebooks/hostfs/Jason's Sandbox/jason_mimc-553_new.csv\")\n",
    "#print (data.head())\n",
    "print (len(data))\n",
    "#null_count=data.isna().sum()\n",
    "#print (null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "read all i2b2 files into a list\n",
    "\"\"\"\n",
    "\n",
    "path=\"/rapids/notebooks/hostfs/i2b2_data/\"\n",
    "files=[]\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "    files += [os.path.join(dirpath, file) for file in filenames]\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 34962: expected 8 fields, saw 9\\nSkipping line 34963: expected 8 fields, saw 9\\nSkipping line 34964: expected 8 fields, saw 9\\n'\n"
     ]
    }
   ],
   "source": [
    "###  Read in Drug Name file sourced from https://www.fda.gov/drugs/drug-approvals-and-databases/drugsfda-data-files\n",
    "\n",
    "drugs=pd.read_csv(r\"/rapids/notebooks/hostfs/Products.txt\",sep=\"\\t\",error_bad_lines=False)\n",
    "drug_list=list(set(drugs[\"DrugName\"]))\n",
    "drg=pd.DataFrame()\n",
    "drg['drugs']=drug_list\n",
    "drg.to_csv('drug_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Open data, extract record id number and add to dataframe\n",
    "\"\"\"\n",
    "df=pd.DataFrame()\n",
    "index=[]\n",
    "record=[]\n",
    "text=[]\n",
    "target=[]\n",
    "count=0\n",
    "\n",
    "###create training set (n=300)\n",
    "for file in files:\n",
    "    index.append(str(count))\n",
    "    with open (file) as f:\n",
    "        x=(str(f.readline()).rstrip())\n",
    "        x=x.split('RECORD')[1]\n",
    "        x=re.split('#',x)[1]\n",
    "        record.append(x)\n",
    "        text.append(str(f.readlines()).replace('\\n', ''))\n",
    "    count+=1\n",
    "df[\"index\"]=index\n",
    "df[\"record_id\"]=record\n",
    "df[\"text\"]=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing Pandas: tokenize text\n",
    "\"\"\"\n",
    "tokens_in_record=[]\n",
    "for record in df['text']:\n",
    "    tokens=sent_tokenize(str(record))\n",
    "    tokens_in_record.append(tokens)\n",
    "df['tokens_in_record']=tokens_in_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering: pull out vitals\n",
    "\"\"\"\n",
    "all_vitals=[]\n",
    "non_vital=[]\n",
    "for record in df[\"text\"]:\n",
    "    \n",
    "    missing=[]\n",
    "    vitals=[]\n",
    "    \n",
    "    sentences=sent_tokenize(str(record))\n",
    "    \n",
    "    for line in sentences:\n",
    "       \n",
    "        if re.findall(r'temperature', str(line)): \n",
    "            junk, temp, keep=str(line).partition('temperature')\n",
    "            vital=temp+keep\n",
    "            vitals.append(vital)\n",
    "            missing.append('na')\n",
    "        if re.findall(r'blood pressure', str(line)):\n",
    "            junk, bp, keep=str(line).partition('blood pressure')\n",
    "            vital=bp+keep\n",
    "            vitals.append(vital)\n",
    "            missing.append('na')\n",
    "        if re.findall(r'breathing',str(line)):\n",
    "            junk, breath, keep=str(line).partition('breathing')\n",
    "            vital=breath+keep\n",
    "            vitals.append(vital)\n",
    "            missing.append('na')\n",
    "        if re.findall(r'respitory',str(line)):\n",
    "            junk, breath, keep=str(line).partition('respitory')\n",
    "            vital=breath+keep\n",
    "            vitals.append(vital)\n",
    "            missing.append('na')\n",
    "        \n",
    "        else:\n",
    "            #vitals.append(line)\n",
    "            continue\n",
    "   \n",
    "    all_vitals.append(vitals)\n",
    "    non_vital.append(missing)\n",
    "    continue\n",
    "   \n",
    "df['non-vitals']=non_vital\n",
    "df['vitals']=all_vitals\n",
    "df.to_csv('test_vitals.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Prep: clean strings\n",
    "\"\"\"\n",
    "\n",
    "df['vitals'] = df['vitals'].replace(r'\\\\n',' ', regex=True)\n",
    "df['non-vitals'] = df['non-vitals'].replace(r'\\\\n',' ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "generate n-grams function\n",
    "\"\"\"\n",
    "def generate_ngrams(s, n):\n",
    "    # Convert to lowercases\n",
    "    s = s.lower()\n",
    "    \n",
    "    # Replace all none alphanumeric characters with spaces\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "    \n",
    "    # Break sentence in the token, remove empty tokens\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "    tokens = [token for token in s.split(\" \") if len(token)>=3]\n",
    "    # Use the zip function to help us generate n-grams\n",
    "    # Concatentate the tokens into ngrams and return\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [blood pressure and this was, pressure and thi...\n",
       "1      [temperature blood pressure 108 pulse, blood p...\n",
       "2      [temperatures were not measured temperature, w...\n",
       "3                                                     []\n",
       "4                                                     []\n",
       "5      [blood pressure room air temperature, pressure...\n",
       "6                                                     []\n",
       "7                                                     []\n",
       "8      [breathing over past few weeks, over past few ...\n",
       "9      [temperature was and heart rate, was and heart...\n",
       "10     [blood pressure 196 jvp bilateral, pressure 19...\n",
       "11                                                    []\n",
       "12     [blood pressure 215 respiratory rate, pressure...\n",
       "13                                                    []\n",
       "14                                                    []\n",
       "15     [breathing meals position nitro and, meals pos...\n",
       "16     [temperatures and touch than the, and touch th...\n",
       "17     [blood pressure improved dramatically with, pr...\n",
       "18     [blood pressure 130 and changes, pressure 130 ...\n",
       "19     [temperature blood pressure temperature blood,...\n",
       "20                                                    []\n",
       "21     [temperature pulse blood pressure 115, pulse b...\n",
       "22     [blood pressure the 50s with, pressure the 50s...\n",
       "23     [blood pressure 186 blood pressure, pressure 1...\n",
       "24                                                    []\n",
       "25     [blood pressure temperature heart rate, pressu...\n",
       "26     [blood pressure 127 and satting, pressure 127 ...\n",
       "27     [temperature was 104 his blood, was 104 his bl...\n",
       "28     [temperature 100 degrees fahrenheit and, 100 d...\n",
       "29     [breathing minimally labored heent perrl, mini...\n",
       "                             ...                        \n",
       "670    [blood pressure the 80s blood, pressure the 80...\n",
       "671    [blood pressure continued drop the, pressure c...\n",
       "672                                                   []\n",
       "673                                                   []\n",
       "674                                                   []\n",
       "675                                                   []\n",
       "676                                                   []\n",
       "677    [blood pressure 140 temperature was, pressure ...\n",
       "678    [blood pressure and was intubated, pressure an...\n",
       "679    [blood pressure was noted systolic, pressure w...\n",
       "680                                                   []\n",
       "681    [blood pressure medications medications her, p...\n",
       "682                                                   []\n",
       "683                                                   []\n",
       "684    [blood pressure 182 systolic hospital, pressur...\n",
       "685    [blood pressure 195 which improved, pressure 1...\n",
       "686    [blood pressure respiratory rate sat, pressure...\n",
       "687    [blood pressure 100 and room, pressure 100 and...\n",
       "688                                                   []\n",
       "689                                                   []\n",
       "690    [breathing discharge condition stable plan, di...\n",
       "691                                                   []\n",
       "692                [blood pressure 130 respiratory rate]\n",
       "693                                                   []\n",
       "694                                                   []\n",
       "695                                                   []\n",
       "696    [blood pressure 130 the right, pressure 130 th...\n",
       "697    [blood pressure was 130 pulse, pressure was 13...\n",
       "698    [temperature 100 slightly foul smelling, 100 s...\n",
       "699    [blood pressure 182 systolic hospital, pressur...\n",
       "Name: clinical_ngrams, Length: 700, dtype: object"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "generate n-grams for df['vitals'] to further refine vitals and prep for topic modelling\n",
    "\"\"\"\n",
    "ngrams=[]\n",
    "for i, row in df.iterrows():\n",
    "    vitals=row['vitals']\n",
    "    clinical_ngrams=generate_ngrams(str(vitals),5)\n",
    "    ngrams.append(clinical_ngrams)\n",
    "\n",
    "df['clinical_ngrams']=ngrams\n",
    "df['clinical_ngrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering: pull out admission details\n",
    "\"\"\"\n",
    "admission_related=[]\n",
    "\n",
    "for record in df[\"text\"]:\n",
    "    sentences=sent_tokenize(str(record))\n",
    "    admit=[]\n",
    "    for line in sentences:\n",
    "        if re.findall(r'admission',str(line)):\n",
    "            admit.append(line)\n",
    "            continue\n",
    "            \n",
    "        elif re.findall(r'admitted',str(line)):\n",
    "            admit.append(line)\n",
    "            continue\n",
    "        elif re.findall(r'admt',str(line)):\n",
    "            admit.append(line)\n",
    "            continue\n",
    "        elif re.findall(r'DOA',str(line)):\n",
    "            admit.append(\"DOA\")\n",
    "            continue   \n",
    "        else:\n",
    "            continue\n",
    "    admission_related.append(admit)\n",
    "df['admission_related']=admission_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [two days prior admission the, days prior admi...\n",
       "1      [sick sinus syndrome status post, sinus syndro...\n",
       "2      [her massive edema was treated, massive edema ...\n",
       "3      [ruled out ischemia and causes, out ischemia a...\n",
       "4      [irreg beats abd surgical scars, beats abd sur...\n",
       "5      [1995 work was negative with, work was negativ...\n",
       "6                                                     []\n",
       "7      [had been bedridden for several, been bedridde...\n",
       "8      [the patient has had prior, patient has had pr...\n",
       "9      [she had previously declined aortic, had previ...\n",
       "10     [the patient was readmitted with, patient was ...\n",
       "11     [presented day admission tni elevation, day ad...\n",
       "12     [chest ray mild pulmonary vascular, ray mild p...\n",
       "13     [she was admitted and treated, was admitted an...\n",
       "14                                                    []\n",
       "15     [none brief resume hospital course, brief resu...\n",
       "16     [insertion pacemaker 2006 history present, pac...\n",
       "17     [857012582 mmh 26868800 4896536 2006, mmh 2686...\n",
       "18     [the patient was last admitted, patient was la...\n",
       "19     [abdominal scan showed that she, scan showed t...\n",
       "20     [the patient states the morning, patient state...\n",
       "21     [the patient was stabilized the, patient was s...\n",
       "22     [342590615 47454253 044574 1998 diverticular, ...\n",
       "23     [the patient presents with multiple, patient p...\n",
       "24     [none brief resume hospital course, brief resu...\n",
       "25     [the night prior admission the, night prior ad...\n",
       "26     [the prior admission was related, prior admiss...\n",
       "27     [the day admission woke with, day admission wo...\n",
       "28     [258792708 12881449 4918469 2006 right, 128814...\n",
       "29     [cont statin lipids afib not, statin lipids af...\n",
       "                             ...                        \n",
       "669    [mulready year old woman with, year old woman ...\n",
       "670    [two days prior admission developed, days prio...\n",
       "671    [ankle osteoarthritis signed dis admission, os...\n",
       "672                                                   []\n",
       "673    [inr admission holding all anticoagulation, ad...\n",
       "674                                                   []\n",
       "675    [had been reasonably active with, been reasona...\n",
       "676    [hemodialysis brief resume hospital course, br...\n",
       "677                                                   []\n",
       "678    [209897154 pmh 15238113 0477274 2003, pmh 1523...\n",
       "679    [286887365 fihmc 41175767 2955396 2007, fihmc ...\n",
       "680    [had echocardiogram which revealed recurrent, ...\n",
       "681    [principal diagnosis vomiting and hypertension...\n",
       "682                                                   []\n",
       "683    [repeat showed stable hematoma with, showed st...\n",
       "684    [353940837 pph 00345636 672382 1999, pph 00345...\n",
       "685    [extremities clubbing cyanosis edema and, club...\n",
       "686    [918306143 bmc 12507329 1206196 2005, bmc 1250...\n",
       "687    [she has been complaining chest, has been comp...\n",
       "688    [left ear deafness operations and, ear deafnes...\n",
       "689    [diuresis brief resume hospital course, brief ...\n",
       "690    [man with known cad with, with known cad with ...\n",
       "691    [none brief resume hospital course, brief resu...\n",
       "692    [urinalysis showed protein ketones blood, show...\n",
       "693    [she was tolerating the chemotherapy, was tole...\n",
       "694    [the patient was placed asa, patient was place...\n",
       "695                                                   []\n",
       "696    [physical examination upon admission height, e...\n",
       "697    [was transferred from jacklip october, transfe...\n",
       "698    [980366409 pnmc 48893008 786110 2000, pnmc 488...\n",
       "Name: admission_ngrams, Length: 699, dtype: object"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "generate n-grams for df['admission_related'] to further refine vitals and prep for topic modelling\n",
    "\"\"\"\n",
    "ngrams=[]\n",
    "for i, row in df.iterrows():\n",
    "    vitals=row['admission_related']\n",
    "    clinical_ngrams=generate_ngrams(str(vitals),5)\n",
    "    ngrams.append(clinical_ngrams)\n",
    "\n",
    "df['admission_ngrams']=ngrams\n",
    "df['admission_ngrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'record_id', 'text', 'tokens_in_record', 'non-vitals',\n",
       "       'vitals', 'clinical_ngrams', 'admission_related', 'admission_ngrams'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [blood_pressure_and_this_was, pressure_and_thi...\n",
       "1      [temperature_blood_pressure_108_pulse, blood_p...\n",
       "2      [temperatures_were_not_measured_temperature, w...\n",
       "3                                                     []\n",
       "4                                                     []\n",
       "5      [blood_pressure_room_air_temperature, pressure...\n",
       "6                                                     []\n",
       "7                                                     []\n",
       "8      [breathing_over_past_few_weeks, over_past_few_...\n",
       "9      [temperature_was_and_heart_rate, was_and_heart...\n",
       "10     [blood_pressure_196_jvp_bilateral, pressure_19...\n",
       "11                                                    []\n",
       "12     [blood_pressure_215_respiratory_rate, pressure...\n",
       "13                                                    []\n",
       "14                                                    []\n",
       "15     [breathing_meals_position_nitro_and, meals_pos...\n",
       "16     [temperatures_and_touch_than_the, and_touch_th...\n",
       "17     [blood_pressure_improved_dramatically_with, pr...\n",
       "18     [blood_pressure_130_and_changes, pressure_130_...\n",
       "19     [temperature_blood_pressure_temperature_blood,...\n",
       "20                                                    []\n",
       "21     [temperature_pulse_blood_pressure_115, pulse_b...\n",
       "22     [blood_pressure_the_50s_with, pressure_the_50s...\n",
       "23     [blood_pressure_186_blood_pressure, pressure_1...\n",
       "24                                                    []\n",
       "25     [blood_pressure_temperature_heart_rate, pressu...\n",
       "26     [blood_pressure_127_and_satting, pressure_127_...\n",
       "27     [temperature_was_104_his_blood, was_104_his_bl...\n",
       "28     [temperature_100_degrees_fahrenheit_and, 100_d...\n",
       "29     [breathing_minimally_labored_heent_perrl, mini...\n",
       "                             ...                        \n",
       "669                [breathing_100_four_liters_breathing]\n",
       "670    [blood_pressure_the_80s_blood, pressure_the_80...\n",
       "671    [blood_pressure_continued_drop_the, pressure_c...\n",
       "672                                                   []\n",
       "673                                                   []\n",
       "674                                                   []\n",
       "675                                                   []\n",
       "676                                                   []\n",
       "677    [blood_pressure_140_temperature_was, pressure_...\n",
       "678    [blood_pressure_and_was_intubated, pressure_an...\n",
       "679    [blood_pressure_was_noted_systolic, pressure_w...\n",
       "680                                                   []\n",
       "681    [blood_pressure_medications_medications_her, p...\n",
       "682                                                   []\n",
       "683                                                   []\n",
       "684    [blood_pressure_182_systolic_hospital, pressur...\n",
       "685    [blood_pressure_195_which_improved, pressure_1...\n",
       "686    [blood_pressure_respiratory_rate_sat, pressure...\n",
       "687    [blood_pressure_100_and_room, pressure_100_and...\n",
       "688                                                   []\n",
       "689                                                   []\n",
       "690    [breathing_discharge_condition_stable_plan, di...\n",
       "691                                                   []\n",
       "692                [blood_pressure_130_respiratory_rate]\n",
       "693                                                   []\n",
       "694                                                   []\n",
       "695                                                   []\n",
       "696    [blood_pressure_130_the_right, pressure_130_th...\n",
       "697    [blood_pressure_was_130_pulse, pressure_was_13...\n",
       "698    [temperature_100_slightly_foul_smelling, 100_s...\n",
       "Name: clinical_ngrams_concat, Length: 699, dtype: object"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "turn ngrams into single 'words' by replacing \" \" with \"_\"\n",
    "\"\"\"\n",
    "clinical_ngrams_concat=[]\n",
    "for i, row in df.iterrows():\n",
    "    ngram_list=[]\n",
    "    ngrams=row['clinical_ngrams']\n",
    "    for n in ngrams:\n",
    "        n=str(n)\n",
    "        a=str(n).replace(\" \",\"_\")\n",
    "        ngram_list.append(a)\n",
    "        continue\n",
    "    clinical_ngrams_concat.append(ngram_list)\n",
    "    continue\n",
    "df['clinical_ngrams_concat']=clinical_ngrams_concat\n",
    "df['clinical_ngrams_concat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ngrams_concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3123\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3124\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3125\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-268-1e810722c31b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mblood_pressure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mngrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ngrams_concat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'blood_pressure'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3130\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3131\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3132\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3133\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3134\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3118\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ngrams_concat'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "pull out blood pressure from clinical ngrams\n",
    "\"\"\"\n",
    "blood_pressure=[]\n",
    "bp=[]\n",
    "for i,row in df.iterrows():\n",
    "    blood_pressure=[]\n",
    "    ngrams=row['ngrams_concat']\n",
    "    if re.match(r'blood_pressure',str(ngrams)):\n",
    "        if ''.join(c for c in str(ngrams) if c.isdigit()):\n",
    "                a=str(row).replace(\"_\",\" \")\n",
    "                # blood pressure 172 70\n",
    "                if re.match(r\"blood pressure \\d{2,3} \\d{2,3}\",a):\n",
    "                    blood_pressure.append(a)\n",
    "                #blood pressure of 172 70\n",
    "                elif re.match(r\"blood pressure.* \\d{2,3} \\d{2,3}\",a):\n",
    "                    a=a.replace('blood pressure', \"\")\n",
    "                    b=re.sub('[a-zA-Z]+',\" \",a)\n",
    "                    blood_pressure.append(b)         \n",
    "                else:\n",
    "                    blood_pressure.append(a)\n",
    "                    \n",
    "        else:\n",
    "            continue\n",
    "        bp.append(blood_pressure)\n",
    "    else:\n",
    "        bp.append(blood_pressure)\n",
    "        i+=1\n",
    "        continue\n",
    "df['bp']=pd.Series(blood_pressure)\n",
    "df['bp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'record_id', 'text', 'tokens_in_record', 'non-vitals',\n",
       "       'vitals', 'clinical_ngrams', 'admission_related', 'admission_ngrams',\n",
       "       'clinical_ngrams_concat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pull out temp, pulse and blood pressure from clinical ngrams\n",
    "\"\"\"\n",
    "bp=[]\n",
    "temperature=[]\n",
    "px=[]\n",
    "for i , row in df.iterrows():\n",
    "    blood_pressure=[]\n",
    "    temp=[]\n",
    "    pulse=[]\n",
    "    ngrams=row['vitals']\n",
    "  \n",
    "    #test=row['tokens_in_record']\n",
    "    \n",
    "    for n in ngrams:\n",
    "        if re.match(r\"(\\bblood pressure)(.*[0-9]\\b)\",str(n)):\n",
    "            match_b=re.search(r\"(\\bblood pressure)(.*[0-9]\\b)\",str(n)).group()\n",
    "            blood_pressure.append(match_b)\n",
    "            \n",
    "        \n",
    "        #if re.match(r\"(\\btemperature)(.*[0-9]\\b)\",str(n)):\n",
    "        try:    \n",
    "            match_t=re.match(r\"(\\btemperature)(.*[0-9]\\b)\",str(n)).group()\n",
    "            temp.append(match_t)\n",
    "        except AttributeError as a:\n",
    "            continue\n",
    "        #if re.match(r\"(\\bpulse)(.*[0-9])\",str(n)):\n",
    "        try:\n",
    "            match_p=re.match(r\"(pulse)(.*[0-9]\\b)\",str(n)).group()\n",
    "            pulse.append(match_p)\n",
    "        except AttributeError as a:\n",
    "            continue\n",
    "        #else:\n",
    "            continue\n",
    "   \n",
    "        #continue\n",
    "\n",
    "    bp.append(blood_pressure)\n",
    "    temperature.append(temp)\n",
    "    px.append(pulse)\n",
    "  \n",
    "df['blood_pressure']=pd.Series(bp)\n",
    "df['pulse']=pd.Series(px)\n",
    "df['temperature']=pd.Series(temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                     0\n",
      "record_id                 0\n",
      "text                      0\n",
      "tokens_in_record          0\n",
      "non-vitals                0\n",
      "vitals                    0\n",
      "clinical_ngrams           0\n",
      "admission_related         0\n",
      "admission_ngrams          0\n",
      "clinical_ngrams_concat    0\n",
      "blood_pressure            0\n",
      "pulse                     0\n",
      "temperature               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_nan = len(df) - df.count()\n",
    "print (count_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "###iterate through tokens and split record\n",
    "admit_related=[]\n",
    "discharge_related=[]\n",
    "\n",
    "for single_record in text:\n",
    "    #single_record_list=sent_tokenize(str(single_record))\n",
    "    admission, word, discharge=str(single_record).partition(\"HOSPITAL COURSE:\")\n",
    "    admit_related.append(admission)\n",
    "    garbage,w,keep=str(admission).partition(\"DISPOSITION\")\n",
    "    discharge_related.append(keep)\n",
    "    continue\n",
    "\n",
    "df['admit_related']=pd.Series(admit_related)\n",
    "df['discharge_related']=pd.Series(discharge_related)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature engineering:medications\n",
    "\"\"\"\n",
    "\n",
    "###  Iterate through text to find matches\n",
    "\n",
    "medications=[]\n",
    "\n",
    "for record in df['text']:\n",
    "    med_list=[]\n",
    "    for drug in drug_list:\n",
    "        if str(drug) in str(record):\n",
    "            med_list.append(drug)         \n",
    "            continue\n",
    "    medications.append(med_list)\n",
    "    continue\n",
    "df['all_meds']=medications\n",
    "#df.to_csv('test-all-meds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering: admission medications\n",
    "\"\"\"\n",
    "meds_on_admission=[]\n",
    "for record in df[\"text\"]:\n",
    "    sentences=sent_tokenize(str(record))\n",
    "    for line in sentences:\n",
    "        if re.search(r'MEDICATIONS', str(line)) and 'ADMISSION' in str(line):\n",
    "            try:\n",
    "                x=str(line).split('ADMISSION:')\n",
    "                x=x[1]\n",
    "                meds_on_admission.append(x)\n",
    "                continue\n",
    "            except IndexError as e:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "   \n",
    "df['meds_on_admission']=pd.Series(meds_on_admission)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering: discharge medications\n",
    "\"\"\"\n",
    "discharge_related=[]\n",
    "for record in df[\"text\"]:\n",
    "    sentences=sent_tokenize(str(record))\n",
    "    for line in sentences:\n",
    "        if re.search(r'MEDICATIONS', str(line)) and 'DISCHARGE' in str(line):\n",
    "            try:\n",
    "                x=str(line).split('DISCHARGE MEDICATIONS:')\n",
    "                x=x[0]\n",
    "                discharge_related.append(x)\n",
    "                continue\n",
    "        \n",
    "            except IndexError as e:\n",
    "                print (e)\n",
    "                continue\n",
    "        else:\n",
    "            continue \n",
    "df['discharge_related']=pd.Series(discharge_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature-engineering: discharge medication context\n",
    "\"\"\"\n",
    "discharge_meds=[]\n",
    "discharge_medication_context=[]\n",
    "for single_record in df[\"discharge_related\"]:\n",
    "    dis_meds=[]\n",
    "    dis_med_cont=[]\n",
    "    sentences=sent_tokenize(str(single_record))\n",
    "    for sentence in sentences:\n",
    "        for drug in drug_list:\n",
    "            if str(drug) in str(sentence):\n",
    "                    dis_med_cont.append(sentence)\n",
    "                    dis_meds.append(drug)\n",
    "                    continue\n",
    "            else:\n",
    "                    continue\n",
    "        continue\n",
    "    discharge_meds.append(dis_meds)\n",
    "    discharge_medication_context.append(dis_med_cont)\n",
    "    \n",
    "df['discharge_medication_context']=discharge_medication_context\n",
    "df['discharge_medications']=discharge_meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('test-discharge-meds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering:principal diagnosis\n",
    "\"\"\"\n",
    "principal_dx=[]\n",
    "for record in text:\n",
    "    try:\n",
    "        d_dx=re.search((\"PRINCIPAL DIAGNOSIS:.*$\"), str(record))\n",
    "        d_dx=str(d_dx).split(\":\")\n",
    "        d_dx=d_dx[1]\n",
    "        d_dx=str(d_dx).split(\".\")\n",
    "        d=d_dx[0]\n",
    "        d=re.sub(r'([^\\s\\w]|_)+', '', d)\n",
    "        principal_dx.append(d)\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        d='n/a'\n",
    "        principal_dx.append(d)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dx']=pd.Series(principal_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "find similar medications based on vectorizing admission related\n",
    "text in the record\n",
    "\"\"\"\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "text=re.sub(r'([^\\s\\w]|_)+', '', str(text))\n",
    "\n",
    "sentences=word_tokenize(str(text))\n",
    "model = Word2Vec([sentences], min_count=1)\n",
    "#vector='infection'\n",
    "#model.similar_by_vector(vector, topn=10, restrict_vocab=None)\n",
    "#model.most_similar_to_given(entity1, entities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=[]\n",
    "context=[]\n",
    "for row in df['text']:\n",
    "    \n",
    "    if re.search('infection',str(row)):\n",
    "        col.append(model.wv.similar_by_word('infection'))\n",
    "        context.append(row)\n",
    "        continue\n",
    "    else:\n",
    "        col.append(0)\n",
    "        context.append(0)\n",
    "        continue\n",
    "df['col']=col\n",
    "df['context']=context\n",
    "df.to_csv('infection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel=[]\n",
    "for row in df['text']:\n",
    "    \n",
    "    if re.findall('YOUKER',str(row)):\n",
    "        rel.append(model.wv.similar_by_word('YOUKER'))\n",
    "        \n",
    "        continue\n",
    "    else:\n",
    "        rel.append(0)\n",
    "        \n",
    "        continue\n",
    "df['rel']=rel\n",
    "df.to_csv('infection2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame()\n",
    "related=[]\n",
    "med_list=[]\n",
    "for med in drug_list:\n",
    "    med_list.append(med)\n",
    "    try:\n",
    "        related.append(model.wv.similar_by_word(str(med)))\n",
    "        continue\n",
    "    except KeyError as a:\n",
    "        related.append('n/a')\n",
    "        continue\n",
    "df2['medication']=med_list\n",
    "df2['related']=related\n",
    "df2.dropna()\n",
    "df2.to_csv(\"med_use.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering: admission date\n",
    "\"\"\"\n",
    "admission_dt=[]\n",
    "#text={'Signed DIS Admission Date: 08/28/06 Report Status: Signed'}\n",
    "for record in text:\n",
    "     try:\n",
    "        x= (re.search((\"Admission Date:.*$\"), str(record)))\n",
    "        x=str(x).split(r'\\\\n')[0]\n",
    "        x=str(x).split(\":\")[1]\n",
    "        x=str(x).split(\" \")[1]\n",
    "        \n",
    "        if x[0]=='2':\n",
    "            x= 'NaT'\n",
    "            admission_dt.append(x)\n",
    "            continue\n",
    "        else:\n",
    "            admission_dt.append(x)\n",
    "     except AttributeError as e:\n",
    "        continue\n",
    "df['admission_dt']=admission_dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering: discharge date\n",
    "\"\"\"\n",
    "discharge_dt=[]\n",
    "for record in text:\n",
    "     try:\n",
    "        x= (re.search((\"Discharge Date:.*$\"), str(record)))\n",
    "        x=str(x).split(r'\\\\n')[0]\n",
    "        x=str(x).split(\":\")[1]\n",
    "        if x[0]==0 or x[2]==0:\n",
    "            x= 'NaT'\n",
    "            discharge_dt.append(x)\n",
    "            continue\n",
    "        else:\n",
    "            discharge_dt.append(x)\n",
    "     except AttributeError as e:\n",
    "            x= 'NaT'\n",
    "            discharge_dt.append(x)\n",
    "            continue\n",
    "     except IndexError as e:\n",
    "            x= 'NaT'\n",
    "            discharge_dt.append(x)\n",
    "            continue\n",
    "df['discharge_dt']=discharge_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering:deceased flag\n",
    "\"\"\"\n",
    "deceased_flag=[]\n",
    "\n",
    "for cell in df['discharge_dt']:\n",
    "    if  'NaT' in str(cell):\n",
    "        deceased_flag.append('1')\n",
    "        continue\n",
    "    \n",
    "    if re.findall(r'pronounced at',str(line),re.I) or re.search(r'pronounced dead',str(line),re.I):\n",
    "        \n",
    "        deceased_flag.append('1')\n",
    "        continue\n",
    "    else:\n",
    "        deceased_flag.append('0')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering:medications\n",
    "\"\"\"\n",
    "medications=[]\n",
    "for record in text:\n",
    "    try:\n",
    "        d_dx=re.findall((\"MEDICATIONS:.*$\"), str(record))\n",
    "        d_dx=str(d_dx).split(\":\")\n",
    "        d_dx=d_dx[1]\n",
    "        d_dx=str(d_dx).split(\".\")\n",
    "        d=d_dx[0]\n",
    "        d=re.sub(r'([^\\s\\w]|_)+', '', d)\n",
    "        medications.append(d)\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        d='n/a'\n",
    "        medications.append(d)\n",
    "        continue\n",
    "df['medications']=medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering:medications 2\n",
    "\"\"\"\n",
    "meds=[]\n",
    "for record in text:\n",
    "    for word in word_tokenize(str(record)):\n",
    "        word=re.sub(r'([^\\s\\w]|_)+', '', str(word))\n",
    "        if word in drug_list:\n",
    "            meds.append(word)\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "                           \n",
    "df['meds']=pd.Series(meds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering: quantified clinical phrases\n",
    "\"\"\"\n",
    "clinical_markers=[]\n",
    "for record in text:\n",
    "    sentences=sent_tokenize(str(record))\n",
    "    for line in sentences:\n",
    "        if re.findall(r'[A-Za-z0-9]', str(line)):\n",
    "            clinical_markers.append(line)\n",
    "            continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering-derived: length of stay\n",
    "\"\"\"\n",
    "df['discharge_dt']=pd.to_datetime(df['discharge_dt'],errors='coerce')\n",
    "df['admission_dt']=pd.to_datetime(df['admission_dt'],errors='coerce')\n",
    "df['discharge_dt'] = df['discharge_dt'].dt.date\n",
    "df['admission_dt'] = df['admission_dt'].dt.date\n",
    "\n",
    "df['length_of_stay']=df['discharge_dt']-df['admission_dt']\n",
    "df['length_of_stay']=abs(df['length_of_stay'])\n",
    "###formatting los and conveting to int\n",
    "los=[]\n",
    "for value in df['length_of_stay']:\n",
    "    try:\n",
    "        value=str(value).split(\" \")\n",
    "        value=int(value[0])\n",
    "        los.append(value)\n",
    "    except ValueError as e:\n",
    "        pass\n",
    "df['los']=pd.Series(los)\n",
    "df['length_of_stay']=df['los']       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "add features to orginal df\n",
    "\"\"\"\n",
    "df['medications']=pd.Series(medications)\n",
    "df[\"admission_dt\"]=admission_dt\n",
    "df[\"discharge_dt\"]=discharge_dt\n",
    "df['principal_dx']=principal_dx\n",
    "df['discharge_related']=pd.Series(discharge_related)\n",
    "df['meds_on_admission']=pd.Series(meds_on_admission)\n",
    "df['deceased_flag']=deceased_flag\n",
    "df['clinical_markers']=pd.Series(clinical_markers)\n",
    "df['length_of_stay']=df['los']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "write parsed data to output file\n",
    "\"\"\"\n",
    "os.chdir(r\"/rapids/notebooks/hostfs/DX-Predictor-Ouput\")\n",
    "df.to_csv('i2b2-parsed-9-13-19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      120.0\n",
       "1      150.0\n",
       "2       32.0\n",
       "3      141.0\n",
       "4       10.0\n",
       "5      259.0\n",
       "6      462.0\n",
       "7      208.0\n",
       "8      297.0\n",
       "9       92.0\n",
       "10      85.0\n",
       "11     177.0\n",
       "12      80.0\n",
       "13      23.0\n",
       "14     291.0\n",
       "15      13.0\n",
       "16     315.0\n",
       "17     145.0\n",
       "18     127.0\n",
       "19     261.0\n",
       "20     240.0\n",
       "21      57.0\n",
       "22      57.0\n",
       "23      87.0\n",
       "24      90.0\n",
       "25      40.0\n",
       "26      76.0\n",
       "27     128.0\n",
       "28      20.0\n",
       "29      38.0\n",
       "       ...  \n",
       "669      NaN\n",
       "670      NaN\n",
       "671      NaN\n",
       "672      NaN\n",
       "673      NaN\n",
       "674      NaN\n",
       "675      NaN\n",
       "676      NaN\n",
       "677      NaN\n",
       "678      NaN\n",
       "679      NaN\n",
       "680      NaN\n",
       "681      NaN\n",
       "682      NaN\n",
       "683      NaN\n",
       "684      NaN\n",
       "685      NaN\n",
       "686      NaN\n",
       "687      NaN\n",
       "688      NaN\n",
       "689      NaN\n",
       "690      NaN\n",
       "691      NaN\n",
       "692      NaN\n",
       "693      NaN\n",
       "694      NaN\n",
       "695      NaN\n",
       "696      NaN\n",
       "697      NaN\n",
       "698      NaN\n",
       "Name: length_of_stay, Length: 699, dtype: float64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length_of_stay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering: use LDA to create additional features from unstructured fields\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: tokenize text function using Spacy\n",
    "\"\"\"\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: prepare text for topic modelling\n",
    "\"\"\"\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 2]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: tokenize clinical markers text\n",
    "\"\"\"\n",
    "clinical_markers_tokens=[]\n",
    "for n in df['clinical_markers']: \n",
    "    clinical_markers_tokens.append(prepare_text_for_lda(str(n)))\n",
    "df['tokens']=clinical_markers_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: tokenize discharge_related text\n",
    "\"\"\"\n",
    "discharge_related_tokens=[]\n",
    "for n in df['discharge_related']: \n",
    "    discharge_related_tokens.append(prepare_text_for_lda(str(n)))\n",
    "df['discharge_related_tokens']=discharge_related_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: tokenize 'ngrams_concat' for topic modelling\n",
    "\"\"\"\n",
    "ngrams_concat_tokens=[]\n",
    "for n in df['ngrams_concat']: \n",
    "    ngrams_concat_tokens.append(prepare_text_for_lda(str(n)))\n",
    "df['ngrams_concat_tokens']=ngrams_concat_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: tokenize 'admission_ngrams_concat' for topic modelling\n",
    "\"\"\"\n",
    "admission_ngrams_concat_tokens=[]\n",
    "for n in df['admission_ngrams_concat']: \n",
    "    admission_ngrams_concat_tokens.append(prepare_text_for_lda(str(n)))\n",
    "df['admission_ngrams_concat_tokens']=admission_ngrams_concat_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: tokenize discharge_medication_context text\n",
    "\"\"\"\n",
    "discharge_medication_context_tokens=[]\n",
    "for n in df['discharge_medication_context']: \n",
    "    discharge_medication_context_tokens.append(prepare_text_for_lda(str(n)))\n",
    "df['discharge_medication_context_tokens']=discharge_medication_context_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: tokenize df['admission_related'] text\n",
    "\"\"\"\n",
    "admission_related_tokens=[]\n",
    "for n in df['admission_related']: \n",
    "    admission_related_tokens.append(prepare_text_for_lda(str(n)))\n",
    "df['admission_related_tokens']=admission_related_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: tokenize medications\n",
    "\"\"\"\n",
    "medication_tokens=[]\n",
    "for n in df['medications']: \n",
    "    medication_tokens.append(prepare_text_for_lda(str(n)))\n",
    "df['medication_tokens']=medication_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: tokenize meds_on_admission\n",
    "\"\"\"\n",
    "meds_on_admission_tokens=[]\n",
    "for n in df['meds_on_admission']: \n",
    "    meds_on_admission_tokens.append(prepare_text_for_lda(str(n)))\n",
    "df['meds_on_admission_tokens']=meds_on_admission_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pre-processing: tokenize all_vitals\n",
    "\"\"\"\n",
    "all_vitals_tokens=[]\n",
    "for n in df['vitals']: \n",
    "    all_vitals_tokens.append(prepare_text_for_lda(str(n)))\n",
    "df['all_vitals_tokens']=all_vitals_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering-derived: use LDA on clinical markers, medications tokens\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['admission_ngrams_concat_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering-derived: use LDA on ngrams_concat\n",
    "create dictionary and corpus and save for future use\n",
    "\"\"\"\n",
    "start=time.time()\n",
    "dictionary = gensim.corpora.Dictionary(df['admission_ngrams_concat_tokens'])\n",
    "\n",
    "#create corpus \n",
    "corpus = [dictionary.doc2bow(text) for text in admission_ngrams_concat_tokens]\n",
    "#save corpus and dictionary\n",
    "pickle.dump(corpus, open('i2b2-corpus.pkl', 'wb'))\n",
    "dictionary.save('i2b2-admission-ngrams_concat.gensim')\n",
    "end=time.time()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['admission_related']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clinical_ngrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering-derived: use LDA on all_vitals\n",
    "create dictionary and corpus and save for future use\n",
    "\"\"\"\n",
    "start=time.time()\n",
    "dictionary = gensim.corpora.Dictionary(df['admission_related_tokens'])\n",
    "\n",
    "#create corpus \n",
    "corpus = [dictionary.doc2bow(text) for text in admission_related_tokens]\n",
    "#save corpus and dictionary\n",
    "pickle.dump(corpus, open('i2b2-corpus.pkl', 'wb'))\n",
    "dictionary.save('i2b2-admission_related.gensim')\n",
    "end=time.time()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering-derived: use LDA on clinical ngrams concat\n",
    "create dictionary and corpus and save for future use\n",
    "\"\"\"\n",
    "start=time.time()\n",
    "dictionary = gensim.corpora.Dictionary(df['clinical_ngrams_concat'])\n",
    "\n",
    "#create corpus \n",
    "corpus = [dictionary.doc2bow(text) for text in clinical_ngrams_concat]\n",
    "#save corpus and dictionary\n",
    "pickle.dump(corpus, open('i2b2-corpus.pkl', 'wb'))\n",
    "dictionary.save('i2b2-admission_related.gensim')\n",
    "end=time.time()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train and save an LDA model\n",
    "use num_topics parameter to determine the number of topics for the model, and num_words parameter for how much to show\n",
    "\"\"\"\n",
    "from gensim import models\n",
    "start=time.time()\n",
    "#model=models.KeyedVectors.load('ft-i2b2-model.gensim')\n",
    "lda=gensim.models.LdaMulticore(corpus=corpus,num_topics=4,id2word=dictionary,passes=100,workers=7)\n",
    "topics=lda.print_topics(num_words=2)\n",
    "end=time.time()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=lda.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print (topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/rapids/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el471331399873812824005099018531\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el471331399873812824005099018531_data = {\"mdsDat\": {\"x\": [0.0911848306501353, -0.10569764018778066, 0.005068607779038164, 0.009444201758607195], \"y\": [0.054680710946741436, 0.04327886502364202, -0.11737207280811858, 0.019412496837735133], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [26.132709503173828, 25.457746505737305, 24.631175994873047, 23.778366088867188]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 7.0, 7.0, 2.0, 3.0, 3.0, 6.0, 8.0, 3.0, 2.0, 2.0, 2.0, 2.300452470779419, 1.7591551542282104, 1.7591551542282104, 1.7591551542282104, 1.759152889251709, 1.7591487169265747, 1.759145975112915, 1.759145975112915, 1.759145975112915, 1.7591233253479004, 1.7590373754501343, 1.7590373754501343, 3.926830530166626, 1.2177735567092896, 1.2177735567092896, 1.2177733182907104, 1.2177735567092896, 1.2177735567092896, 1.2177733182907104, 1.2177733182907104, 1.2177733182907104, 1.2177735567092896, 1.2177733182907104, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 1.2177735567092896, 3.3850772380828857, 1.2177735567092896, 3.928741931915283, 3.928741931915283, 3.3841352462768555, 1.2177735567092896, 3.9308955669403076, 1.7605953216552734, 3.9285337924957275, 2.3049139976501465, 2.305452346801758, 1.7617303133010864, 1.2177735567092896, 1.2177733182907104, 1.2177733182907104, 1.7745481729507446, 1.7657934427261353, 1.7593815326690674, 1.2177727222442627, 1.2177727222442627, 1.2177727222442627, 1.221777319908142, 1.2214341163635254, 1.2209434509277344, 1.2196521759033203, 1.7366387844085693, 1.7366331815719604, 1.202193021774292, 1.202193021774292, 1.202193021774292, 1.202193021774292, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 2.2715492248535156, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.2021915912628174, 1.7389146089553833, 1.738907814025879, 1.737661600112915, 1.737661600112915, 1.737661600112915, 2.2659966945648193, 1.736930251121521, 1.2072230577468872, 1.20608651638031, 1.204367756843567, 1.203890323638916, 1.202431082725525, 1.2022523880004883, 1.2022161483764648, 1.2022089958190918, 1.2022089958190918, 3.282325267791748, 3.282325267791748, 3.282325267791748, 2.2318880558013916, 2.2318813800811768, 2.2318813800811768, 2.2318813800811768, 2.2318813800811768, 2.2318813800811768, 1.7066744565963745, 1.706671118736267, 1.706664800643921, 1.706664800643921, 3.284799814224243, 3.282703161239624, 1.1814464330673218, 1.1814464330673218, 1.1814464330673218, 1.181443691253662, 1.181443691253662, 1.181443691253662, 1.181443691253662, 1.1814414262771606, 1.1814414262771606, 1.1814414262771606, 1.1814414262771606, 1.1814414262771606, 1.1814414262771606, 1.1814414262771606, 1.1814414262771606, 1.1814414262771606, 1.1814414262771606, 2.2323410511016846, 1.7066394090652466, 1.7066394090652466, 3.797386646270752, 3.811452627182007, 1.7077147960662842, 1.723551630973816, 1.704899549484253, 1.707938551902771, 1.6997532844543457, 1.6997532844543457, 1.186492919921875, 1.1846712827682495, 1.1839131116867065, 1.1837735176086426, 3.2315399646759033, 2.7144501209259033, 2.714440107345581, 2.1973490715026855, 1.680227518081665, 1.1631628274917603, 1.1631628274917603, 1.163162112236023, 1.163162112236023, 1.163162112236023, 1.163162112236023, 1.163162112236023, 1.1631596088409424, 1.1631596088409424, 1.1631596088409424, 1.1631596088409424, 1.1631596088409424, 1.1631596088409424, 1.1631596088409424, 1.1631596088409424, 1.163156270980835, 1.163156270980835, 1.163156270980835, 1.163156270980835, 1.163156270980835, 1.163156270980835, 1.163156270980835, 1.163156270980835, 1.163156270980835, 1.163156270980835, 2.198227882385254, 2.1972758769989014, 2.7176413536071777, 2.714674711227417, 1.6823465824127197, 1.6802937984466553, 2.1990952491760254, 2.724992513656616, 1.163155436515808, 1.163155436515808, 1.163155436515808, 1.163155436515808, 1.682714581489563, 1.163155436515808, 1.683123230934143, 1.683123230934143, 1.1660672426223755, 1.165503740310669, 1.1647487878799438, 1.164331316947937, 1.164154052734375, 1.1638845205307007, 1.1638845205307007, 1.163814663887024, 1.1637110710144043, 1.1637003421783447, 1.1635172367095947], \"Term\": [\"give_units_subcutaneously_blood_sugar\", \"saturation_room_air_cardiovascular_regular\", \"room_air_cardiovascular_regular_rate\", \"air_cardiovascular_regular_rate_and\", \"respiratory_rate_and_oxygen_saturation\", \"regular_rate_and_rhythm_with\", \"cardiovascular_regular_rate_and_rhythm\", \"then_give_units_subcutaneously_blood\", \"respiratory_rate_oxygen_saturation_100\", \"oxygen_saturation_room_air_blood\", \"blood_pressure_130_respiratory_rate\", \"blood_pressure_140_respiratory_rate\", \"rate_oxygen_saturation_100_room\", \"oxygen_saturation_room_air_cardiovascular\", \"heart_rate_and_regular_blood\", \"rate_and_regular_blood_pressure\", \"regular_blood_pressure_right_arm\", \"temperature_heart_rate_and_regular\", \"and_regular_blood_pressure_right\", \"respiratory_rate_oxygen_saturation_room\", \"rate_oxygen_saturation_room_air\", \"blood_pressure_120_respiratory_rate\", \"oxygen_saturation_100_room_air\", \"blood_pressure_and_heart_rate\", \"blood_pressure_the_right_arm\", \"blood_pressure_less_than_100\", \"blood_pressure_160_respiratory_rate\", \"respiratory_rate_and_saturating_liters\", \"mouth_every_hours_needed_for\", \"breathing_with_room_air_saturation\", \"blood_pressure_120_respiratory_rate\", \"breathing_times_minute_and_satting\", \"times_minute_and_satting_100\", \"minute_and_satting_100_nonrebreather\", \"130_respiratory_rate_and_oxygen\", \"rate_and_oxygen_saturation_100\", \"air_and_respiratory_rate_blood\", \"room_air_and_respiratory_rate\", \"saturation_room_air_and_respiratory\", \"respiratory_rate_oxygen_saturation_liters\", \"pressure_respiratory_rate_oxygen_saturation\", \"blood_pressure_respiratory_rate_oxygen\", \"respiratory_rate_and_oxygen_saturation\", \"preoperative_weight_listed_kilograms_flap\", \"remains_place_draining_fluid_yesterday\", \"120_respiratory_rate_100_100\", \"room_air_and_today_weight\", \"pressure_110_oxygen_saturation_room\", \"pressure_120_respiratory_rate_100\", \"rate_100_100_face_mask\", \"100_100_face_mask_blood\", \"and_today_weight_listed_kilograms\", \"respiratory_rate_100_100_face\", \"place_draining_fluid_yesterday_and\", \"saturation_room_air_and_today\", \"listed_kilograms_note_preoperative_weight\", \"listed_kilograms_flap_drain_remains\", \"kilograms_note_preoperative_weight_listed\", \"110_oxygen_saturation_room_air\", \"air_and_today_weight_listed\", \"note_preoperative_weight_listed_kilograms\", \"today_weight_listed_kilograms_note\", \"blood_pressure_110_oxygen_saturation\", \"drain_remains_place_draining_fluid\", \"draining_fluid_yesterday_and_the\", \"flap_drain_remains_place_draining\", \"kilograms_flap_drain_remains_place\", \"fluid_yesterday_and_the_time\", \"oxygen_saturation_room_air_blood\", \"yesterday_and_the_time_discharge\", \"rate_oxygen_saturation_room_air\", \"respiratory_rate_oxygen_saturation_room\", \"blood_pressure_the_right_arm\", \"weight_listed_kilograms_note_preoperative\", \"temperature_heart_rate_blood_pressure\", \"room_air_blood_pressure_and\", \"saturation_room_air_blood_pressure\", \"and_respiratory_rate_blood_pressure\", \"blood_pressure_110_respiratory_rate\", \"blood_pressure_132_respiratory_rate\", \"weight_listed_kilograms_flap_drain\", \"151_respiratory_rate_oxygen_saturation\", \"124_151_respiratory_rate_oxygen\", \"and_oxygen_saturation_room_air\", \"equal_round_and_reactive_light\", \"room_air_blood_pressure_was\", \"pressure_140_pulse_saturation_room\", \"blood_pressure_140_pulse_saturation\", \"pulse_saturation_room_air_and\", \"were_equal_round_and_reactive\", \"blood_pressure_the_left_arm\", \"oxygen_saturation_room_air_and\", \"rate_and_oxygen_saturation_room\", \"and_was_saturating_room_air\", \"temperature_heart_rate_respiratory_rate\", \"blood_pressure_and_weight_and\", \"weight_and_call_earl_frankiewicz\", \"and_weight_and_call_earl\", \"pressure_and_weight_and_call\", \"jugular_venous_pressure_chest_showed\", \"rales_two_thirds_the_way\", \"pulse_101_and_respiratory_rates\", \"pressure_chest_showed_bilateral_rales\", \"pressure_108_pulse_101_and\", \"liters_heent_examination_revealed_jugular\", \"chest_showed_bilateral_rales_two\", \"heent_examination_revealed_jugular_venous\", \"examination_revealed_jugular_venous_pressure\", \"respiratory_rates_with_saturations_three\", \"bilateral_rales_two_thirds_the\", \"and_respiratory_rates_with_saturations\", \"108_pulse_101_and_respiratory\", \"101_and_respiratory_rates_with\", \"rates_with_saturations_three_liters\", \"blood_pressure_108_pulse_101\", \"revealed_jugular_venous_pressure_chest\", \"venous_pressure_chest_showed_bilateral\", \"without_wheezes_and_focal_findings\", \"with_saturations_three_liters_heent\", \"showed_bilateral_rales_two_thirds\", \"way_without_wheezes_and_focal\", \"wheezes_and_focal_findings_egophony\", \"two_thirds_the_way_without\", \"blood_pressure_160_respiratory_rate\", \"the_way_without_wheezes_and\", \"saturations_three_liters_heent_examination\", \"thirds_the_way_without_wheezes\", \"three_liters_heent_examination_revealed\", \"saturating_room_air_blood_pressure\", \"was_saturating_room_air_blood\", \"condition_stable_plan_dictated_summary\", \"stable_plan_dictated_summary_entered\", \"discharge_condition_stable_plan_dictated\", \"temperature_heart_rate_blood_pressure\", \"room_air_blood_pressure_was\", \"respiratory_rate_and_saturation_liters\", \"oxygen_saturation_was_room_air\", \"saturations_room_air_blood_pressure\", \"respiratory_rate_sat_room_air\", \"blood_pressure_control_blood_pressure\", \"room_air_saturation_blood_pressure\", \"with_room_air_saturation_blood\", \"respiratory_rate_with_room_air\", \"rate_with_room_air_saturation\", \"air_cardiovascular_regular_rate_and\", \"room_air_cardiovascular_regular_rate\", \"saturation_room_air_cardiovascular_regular\", \"oxygen_saturation_room_air_cardiovascular\", \"temperature_heart_rate_and_regular\", \"heart_rate_and_regular_blood\", \"rate_and_regular_blood_pressure\", \"and_regular_blood_pressure_right\", \"regular_blood_pressure_right_arm\", \"mouth_every_hours_needed_for\", \"breathing_with_room_air_saturation\", \"respiratory_rate_and_saturation_room\", \"rate_and_saturation_room_air\", \"regular_rate_and_rhythm_with\", \"cardiovascular_regular_rate_and_rhythm\", \"150_milligrams_mouth_twice_day\", \"pressure_108_oxygen_saturation_liters\", \"108_oxygen_saturation_liters_nasal\", \"150_and_breathing_with_room\", \"blood_pressure_150_and_breathing\", \"pressure_150_and_breathing_with\", \"and_breathing_with_room_air\", \"pressure_was_130_respirations_were\", \"respirations_were_and_sating_room\", \"sating_room_air_blood_pressure\", \"respiratory_rate_sating_room_air\", \"blood_pressure_was_130_respirations\", \"pressure_138_respiratory_rate_sating\", \"were_and_sating_room_air\", \"138_respiratory_rate_sating_room\", \"was_130_respirations_were_and\", \"130_respirations_were_and_sating\", \"satting_room_air_blood_pressure\", \"room_air_blood_pressure_less\", \"air_blood_pressure_less_than\", \"blood_pressure_less_than_100\", \"saturation_room_air_blood_pressure\", \"room_air_saturation_blood_pressure\", \"and_oxygen_saturation_room_air\", \"oxygen_saturation_room_air_blood\", \"blood_pressure_the_right_arm\", \"rate_oxygen_saturation_room_air\", \"respiratory_rate_oxygen_saturation_room\", \"respiratory_rate_satting_room_air\", \"blood_pressure_108_oxygen_saturation\", \"pressure_110_respiratory_rate_and\", \"pressure_the_right_arm_140\", \"give_units_subcutaneously_blood_sugar\", \"then_give_units_subcutaneously_blood\", \"respiratory_rate_oxygen_saturation_100\", \"rate_oxygen_saturation_100_room\", \"respiratory_rate_and_saturating_liters\", \"pressure_room_air_sat_was\", \"blood_pressure_room_air_sat\", \"temperature_saturations_and_and_examination\", \"saturations_and_and_examination_was\", \"examination_was_within_normal_limits\", \"and_examination_was_within_normal\", \"and_and_examination_was_within\", \"118_140_heart_rate_respiratory\", \"140_heart_rate_respiratory_rate\", \"rate_respiratory_rate_oxygen_saturation\", \"100_room_air_100_weight\", \"blood_pressure_118_140_heart\", \"pressure_118_140_heart_rate\", \"heart_rate_respiratory_rate_oxygen\", \"saturation_100_room_air_100\", \"saturation_room_air_general_appearance\", \"gentleman_apparent_distress_with_bilateral\", \"general_appearance_elderly_looking_gentleman\", \"room_air_general_appearance_elderly\", \"elderly_looking_gentleman_apparent_distress\", \"distress_with_bilateral_hearing_aids\", \"looking_gentleman_apparent_distress_with\", \"air_general_appearance_elderly_looking\", \"appearance_elderly_looking_gentleman_apparent\", \"apparent_distress_with_bilateral_hearing\", \"oxygen_saturation_100_room_air\", \"blood_pressure_and_heart_rate\", \"blood_pressure_130_respiratory_rate\", \"blood_pressure_140_respiratory_rate\", \"temperature_pulse_blood_pressure_140\", \"pressure_less_than_100_heart\", \"liters_nasal_cannula_blood_pressure\", \"blood_pressure_less_than_100\", \"pressure_115_respiratory_rate_and\", \"rate_and_saturations_liters_oxygen\", \"respiratory_rate_and_saturations_liters\", \"saturations_liters_oxygen_with_liters\", \"and_respiratory_rate_blood_pressure\", \"and_saturations_liters_oxygen_with\", \"rate_oxygen_saturation_room_air\", \"respiratory_rate_oxygen_saturation_room\", \"equal_round_and_reactive_light\", \"blood_pressure_150_respiratory_rate\", \"rate_saturation_room_air_blood\", \"saturation_liters_nasal_cannula_blood\", \"respiratory_rate_saturation_room_air\", \"pressure_150_respiratory_rate_oxygen\", \"150_respiratory_rate_oxygen_saturation\", \"blood_pressure_control_blood_pressure\", \"systolic_blood_pressure_less_than\", \"oxygen_saturation_room_air_general\", \"oxygen_saturation_liters_nasal_cannula\"], \"Total\": [3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 7.0, 7.0, 2.0, 3.0, 3.0, 6.0, 8.0, 3.0, 2.0, 2.0, 2.0, 2.6946940422058105, 2.1533474922180176, 2.1533474922180176, 2.1533474922180176, 2.153346538543701, 2.1533451080322266, 2.153343677520752, 2.153343677520752, 2.153343677520752, 2.1533355712890625, 2.1533031463623047, 2.1533031463623047, 4.852969169616699, 1.6119648218154907, 1.6119648218154907, 1.6119645833969116, 1.6119648218154907, 1.6119648218154907, 1.6119645833969116, 1.6119645833969116, 1.6119645833969116, 1.6119648218154907, 1.6119645833969116, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 1.6119648218154907, 5.352883338928223, 1.6119648218154907, 7.445254325866699, 7.445254325866699, 6.386741638183594, 1.6119648218154907, 8.015202522277832, 2.6874547004699707, 10.097590446472168, 4.770674228668213, 4.795875072479248, 3.212191343307495, 1.6119648218154907, 1.6119645833969116, 1.6119645833969116, 4.262600421905518, 4.246378421783447, 4.281287670135498, 1.6119643449783325, 1.6119643449783325, 1.6119643449783325, 2.136937141418457, 2.653702735900879, 2.128847360610962, 2.1368587017059326, 2.1325650215148926, 2.132563352584839, 1.5981148481369019, 1.5981148481369019, 1.5981148481369019, 1.5981148481369019, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 3.1838014125823975, 1.598114252090454, 1.598114252090454, 1.598114252090454, 1.598114252090454, 2.6494016647338867, 2.6494007110595703, 3.190323829650879, 3.190323829650879, 3.190323829650879, 8.015202522277832, 4.281287670135498, 2.1149911880493164, 2.1230239868164062, 2.1390888690948486, 2.632037401199341, 3.697917938232422, 3.6902668476104736, 3.1650402545928955, 2.632002353668213, 2.632002353668213, 3.680558443069458, 3.680558443069458, 3.680558443069458, 2.6301207542419434, 2.6301181316375732, 2.6301181316375732, 2.6301181316375732, 2.6301181316375732, 2.6301181316375732, 2.1049017906188965, 2.104900360107422, 2.10489821434021, 2.10489821434021, 4.197366714477539, 4.214661121368408, 1.5796740055084229, 1.5796740055084229, 1.5796740055084229, 1.5796730518341064, 1.5796730518341064, 1.5796730518341064, 1.5796730518341064, 1.5796722173690796, 1.5796722173690796, 1.5796722173690796, 1.5796722173690796, 1.5796722173690796, 1.5796722173690796, 1.5796722173690796, 1.5796722173690796, 1.5796722173690796, 1.5796722173690796, 3.70523738861084, 2.6389975547790527, 2.6389975547790527, 8.400343894958496, 10.097590446472168, 3.6902668476104736, 4.262600421905518, 5.352883338928223, 6.386741638183594, 7.445254325866699, 7.445254325866699, 2.1136162281036377, 2.0964653491973877, 2.6374289989471436, 2.096451997756958, 3.6317989826202393, 3.1147091388702393, 3.114706039428711, 2.5976150035858154, 2.080512046813965, 1.5634253025054932, 1.5634253025054932, 1.5634249448776245, 1.5634249448776245, 1.5634249448776245, 1.5634249448776245, 1.5634249448776245, 1.5634242296218872, 1.5634242296218872, 1.5634242296218872, 1.5634242296218872, 1.5634242296218872, 1.5634242296218872, 1.5634242296218872, 1.5634242296218872, 1.5634231567382812, 1.5634231567382812, 1.5634231567382812, 1.5634231567382812, 1.5634231567382812, 1.5634231567382812, 1.5634231567382812, 1.5634231567382812, 1.5634231567382812, 1.5634231567382812, 3.1385996341705322, 3.1386356353759766, 4.196907043457031, 4.197122097015381, 2.6053600311279297, 2.621541738510132, 5.273438930511475, 8.400343894958496, 1.563422679901123, 1.563422679901123, 1.563422679901123, 1.563422679901123, 4.770674228668213, 1.563422679901123, 7.445254325866699, 7.445254325866699, 4.246378421783447, 3.1707022190093994, 3.163403034210205, 3.163363456726074, 4.2300801277160645, 2.6458139419555664, 2.6458139419555664, 3.697917938232422, 2.6224045753479004, 2.1044201850891113, 4.230031967163086], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1837999820709229, 1.139799952507019, 1.139799952507019, 1.139799952507019, 1.139799952507019, 1.139799952507019, 1.139799952507019, 1.139799952507019, 1.139799952507019, 1.139799952507019, 1.1397000551223755, 1.1397000551223755, 1.1302000284194946, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 0.8837000131607056, 1.0615999698638916, 0.7027000188827515, 0.7027000188827515, 0.7069000005722046, 1.0615999698638916, 0.6294999718666077, 0.9190000295639038, 0.39800000190734863, 0.6144999861717224, 0.609499990940094, 0.7412999868392944, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 0.46560001373291016, 0.4645000100135803, 0.4526999890804291, 1.0615999698638916, 1.0615999698638916, 1.0615999698638916, 0.7828999757766724, 0.566100001335144, 0.7860000133514404, 0.7811999917030334, 1.1627999544143677, 1.1627999544143677, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.030500054359436, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 1.0835000276565552, 0.9470999836921692, 0.9470999836921692, 0.7605999708175659, 0.7605999708175659, 0.7605999708175659, 0.10480000078678131, 0.4659999907016754, 0.8073999881744385, 0.8026999831199646, 0.7936999797821045, 0.5860000252723694, 0.24469999969005585, 0.24660000205039978, 0.4002000093460083, 0.5845999717712402, 0.5845999717712402, 1.2865999937057495, 1.2865999937057495, 1.2865999937057495, 1.2369999885559082, 1.2369999885559082, 1.2369999885559082, 1.2369999885559082, 1.2369999885559082, 1.2369999885559082, 1.1914000511169434, 1.1914000511169434, 1.1914000511169434, 1.1914000511169434, 1.156000018119812, 1.1512999534606934, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 1.110700011253357, 0.8945000171661377, 0.9653000235557556, 0.9653000235557556, 0.607200026512146, 0.4268999993801117, 0.6305999755859375, 0.49570000171661377, 0.25699999928474426, 0.08219999819993973, -0.07590000331401825, -0.07590000331401825, 0.8238000273704529, 0.8303999900817871, 0.6001999974250793, 0.8295999765396118, 1.319599986076355, 1.298799991607666, 1.298799991607666, 1.2690999507904053, 1.2226999998092651, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.080299973487854, 1.079800009727478, 1.0017999410629272, 1.0006999969482422, 0.9990000128746033, 0.991599977016449, 0.5618000030517578, 0.31060001254081726, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 1.1406999826431274, 0.39430001378059387, 1.1406999826431274, -0.05050000175833702, -0.05050000175833702, 0.14399999380111694, 0.43560001254081726, 0.4372999966144562, 0.43689998984336853, 0.1462000012397766, 0.6151999831199646, 0.6151999831199646, 0.28029999136924744, 0.6238999962806702, 0.843999981880188, 0.14560000598430634], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.89139986038208, -7.1596999168396, -7.1596999168396, -7.1596999168396, -7.1596999168396, -7.1596999168396, -7.1596999168396, -7.1596999168396, -7.1596999168396, -7.1596999168396, -7.1596999168396, -7.1596999168396, -6.3566999435424805, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.527500152587891, -6.505099773406982, -7.527500152587891, -6.356200218200684, -6.356200218200684, -6.50540018081665, -7.527500152587891, -6.355599880218506, -7.15880012512207, -6.356200218200684, -6.889400005340576, -6.889200210571289, -7.158199787139893, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.150899887084961, -7.155900001525879, -7.1595001220703125, -7.527500152587891, -7.527500152587891, -7.527500152587891, -7.524199962615967, -7.524499893188477, -7.524899959564209, -7.525899887084961, -7.146399974822998, -7.146399974822998, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -6.877900123596191, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.514200210571289, -7.145100116729736, -7.145100116729736, -7.1458001136779785, -7.1458001136779785, -7.1458001136779785, -6.880300045013428, -7.146200180053711, -7.510000228881836, -7.510900020599365, -7.512400150299072, -7.512800216674805, -7.513999938964844, -7.514100074768066, -7.514200210571289, -7.514200210571289, -7.514200210571289, -6.476799964904785, -6.476799964904785, -6.476799964904785, -6.862500190734863, -6.862500190734863, -6.862500190734863, -6.862500190734863, -6.862500190734863, -6.862500190734863, -7.130799770355225, -7.130799770355225, -7.130799770355225, -7.130799770355225, -6.47599983215332, -6.476600170135498, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -7.498600006103516, -6.862299919128418, -7.130799770355225, -7.130799770355225, -6.330999851226807, -6.327300071716309, -7.130199909210205, -7.1209001541137695, -7.131800174713135, -7.130000114440918, -7.134799957275391, -7.134799957275391, -7.49429988861084, -7.495800018310547, -7.496500015258789, -7.496600151062012, -6.457099914550781, -6.631499767303467, -6.631499767303467, -6.842800140380859, -7.111100196838379, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -6.842400074005127, -6.842899799346924, -6.630300045013428, -6.631400108337402, -7.109899997711182, -7.111100196838379, -6.8420000076293945, -6.627600193023682, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.478899955749512, -7.1097002029418945, -7.478899955749512, -7.109399795532227, -7.109399795532227, -7.476399898529053, -7.476900100708008, -7.47760009765625, -7.47790002822876, -7.478099822998047, -7.478300094604492, -7.478300094604492, -7.478400230407715, -7.478499889373779, -7.478499889373779, -7.478600025177002]}, \"token.table\": {\"Topic\": [1, 4, 2, 3, 2, 1, 4, 1, 1, 3, 1, 3, 4, 3, 3, 1, 4, 1, 1, 1, 2, 3, 3, 4, 4, 3, 4, 1, 2, 3, 3, 1, 3, 4, 2, 4, 1, 2, 2, 4, 4, 2, 3, 4, 2, 1, 1, 2, 3, 4, 4, 1, 1, 4, 1, 2, 3, 1, 1, 4, 3, 1, 3, 4, 2, 4, 1, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 1, 3, 4, 1, 3, 4, 3, 1, 3, 2, 3, 2, 1, 2, 4, 1, 2, 4, 4, 1, 1, 4, 1, 2, 3, 4, 2, 4, 1, 1, 4, 4, 4, 3, 4, 2, 2, 1, 1, 1, 1, 2, 1, 2, 3, 4, 4, 1, 3, 1, 1, 4, 1, 2, 3, 4, 1, 4, 1, 3, 3, 1, 4, 2, 3, 1, 1, 3, 2, 1, 1, 3, 4, 4, 4, 1, 3, 1, 3, 1, 4, 2, 2, 1, 4, 1, 4, 3, 4, 3, 2, 1, 2, 1, 1, 1, 3, 3, 3, 4, 4, 1, 3, 4, 4, 1, 2, 3, 4, 2, 4, 2, 3, 3, 4, 1, 3, 1, 1, 2, 4, 2, 4, 3, 4, 4, 1, 1, 3, 4, 2, 4, 3, 2, 3, 1, 2, 3, 4, 2, 4, 2, 2, 1, 1, 1, 2, 2, 3, 1, 2, 3, 3, 4, 2, 3, 4, 3, 1, 2, 3, 2, 4, 4, 1, 2, 3, 4, 1, 1, 1, 2, 3, 4, 3, 4, 4, 4, 1, 2, 2, 2, 1, 2, 4, 2, 3, 4, 3, 1, 2, 3, 4, 2, 3, 4, 4, 2, 4, 2, 2, 1, 1, 2, 2, 3, 2, 4, 2, 2, 1, 1, 3, 1, 3, 2, 2, 3, 4, 2, 2, 1], \"Freq\": [0.6203610301017761, 0.6396216750144958, 0.6257374882698059, 0.6330419778823853, 0.6257374882698059, 0.6203609108924866, 0.6396216750144958, 0.6203610301017761, 0.6203610301017761, 0.6330426931381226, 0.9287868738174438, 0.6330426931381226, 0.6396216750144958, 0.6330423951148987, 0.6330419778823853, 0.37795552611351013, 0.37795552611351013, 0.6203610301017761, 0.9287881255149841, 0.6203609108924866, 0.37893176078796387, 0.7578635215759277, 0.8150936961174011, 0.6396220922470093, 0.639621376991272, 0.6330423951148987, 0.639621376991272, 0.469197154045105, 0.2345985770225525, 0.469197154045105, 0.7604221105575562, 0.4192279577255249, 0.20961397886276245, 0.4192279577255249, 0.6257374882698059, 0.6396222710609436, 0.6203609108924866, 0.9378377795219421, 0.6257372498512268, 0.6396220922470093, 0.6396220922470093, 0.6257374882698059, 0.4769933223724365, 0.4769933223724365, 0.6257374882698059, 0.6203609108924866, 0.41702502965927124, 0.20851251482963562, 0.20851251482963562, 0.20851251482963562, 0.6396216750144958, 0.7421993017196655, 0.23827069997787476, 0.7148120999336243, 0.6226279139518738, 0.3113139569759369, 0.3113139569759369, 0.6203610897064209, 0.238258495926857, 0.7147755026817322, 0.6330423951148987, 0.3153875470161438, 0.3153875470161438, 0.3153875470161438, 0.6281799077987671, 0.31408995389938354, 0.3186097741127014, 0.6372195482254028, 0.6257372498512268, 0.27042242884635925, 0.27042242884635925, 0.27042242884635925, 0.27042242884635925, 0.11904274672269821, 0.11904274672269821, 0.47617098689079285, 0.35712823271751404, 0.9288055896759033, 0.6396211981773376, 0.37683194875717163, 0.37683194875717163, 0.37683194875717163, 0.46972307562828064, 0.31314873695373535, 0.15657436847686768, 0.6330426931381226, 0.9287864565849304, 0.950163722038269, 0.23726700246334076, 0.7118009924888611, 0.6257374882698059, 0.3134478032588959, 0.6268956065177917, 0.3134478032588959, 0.3134478032588959, 0.6268956065177917, 0.3134478032588959, 0.6396220922470093, 0.6203609108924866, 0.6203609108924866, 0.6396220922470093, 0.4709895849227905, 0.23549479246139526, 0.23549479246139526, 0.23549479246139526, 0.6257374882698059, 0.639621376991272, 0.6203609108924866, 0.6203609108924866, 0.6396220922470093, 0.6396220922470093, 0.8260369300842285, 0.7604221105575562, 0.6396216750144958, 0.6257374882698059, 0.6257374882698059, 0.6203609108924866, 0.6203609108924866, 0.6203609108924866, 0.6203609108924866, 0.6257374882698059, 0.18962958455085754, 0.18962958455085754, 0.18962958455085754, 0.3792591691017151, 0.6396220922470093, 0.9287864565849304, 0.9501630663871765, 0.6203609108924866, 0.3186134397983551, 0.6372268795967102, 0.23640483617782593, 0.23640483617782593, 0.23640483617782593, 0.23640483617782593, 0.4697377681732178, 0.4697377681732178, 0.5604456067085266, 0.3736304044723511, 0.7604213356971741, 0.47519028186798096, 0.47519028186798096, 0.4710262417793274, 0.4710262417793274, 0.6203609108924866, 0.6203609108924866, 0.6330419778823853, 0.6257374882698059, 0.6203609108924866, 0.3791571259498596, 0.3791571259498596, 0.3791571259498596, 0.6396222710609436, 0.6396216750144958, 0.6203610301017761, 0.6330426931381226, 0.6203610897064209, 0.6330423951148987, 0.37795552611351013, 0.37795552611351013, 0.6257372498512268, 0.6257374882698059, 0.3814549148082733, 0.7629098296165466, 0.9288055896759033, 0.6396211981773376, 0.47699636220932007, 0.47699636220932007, 0.6330426931381226, 0.6257374882698059, 0.6203610897064209, 0.6257374882698059, 0.6203610301017761, 0.9287874698638916, 0.4679766595363617, 0.4679766595363617, 0.7604221105575562, 0.9501647353172302, 0.6396222710609436, 0.7699370384216309, 0.5372549891471863, 0.26862749457359314, 0.26862749457359314, 0.6396216750144958, 0.31611526012420654, 0.31611526012420654, 0.31611526012420654, 0.31611526012420654, 0.37993887066841125, 0.37993887066841125, 0.6257374882698059, 0.7604221105575562, 0.7147338390350342, 0.23824460804462433, 0.6203609108924866, 0.6330426931381226, 0.6203610301017761, 0.8242376446723938, 0.20605941116809845, 0.9613018035888672, 0.47281521558761597, 0.47281521558761597, 0.9501647353172302, 0.6396222710609436, 0.9631727337837219, 0.9287915825843811, 0.5372549891471863, 0.26862749457359314, 0.26862749457359314, 0.37993380427360535, 0.37993380427360535, 0.6330426931381226, 0.473122775554657, 0.473122775554657, 0.23640213906764984, 0.23640213906764984, 0.23640213906764984, 0.23640213906764984, 0.37993887066841125, 0.37993887066841125, 0.6257374882698059, 0.6257374882698059, 0.9287881255149841, 0.6203609108924866, 0.7441985607147217, 0.37209928035736084, 0.37893176078796387, 0.7578635215759277, 0.46714916825294495, 0.46714916825294495, 0.23357458412647247, 0.8150936961174011, 0.6396220922470093, 0.27098309993743896, 0.5419661998748779, 0.27098309993743896, 0.6330426931381226, 0.2698882520198822, 0.2698882520198822, 0.5397765040397644, 0.7548874020576477, 0.37744370102882385, 0.6396216750144958, 0.3161192238330841, 0.3161192238330841, 0.3161192238330841, 0.3161192238330841, 0.9287881255149841, 0.6203609108924866, 0.3961341083049774, 0.09903352707624435, 0.3961341083049774, 0.09903352707624435, 0.8150936961174011, 0.6396220922470093, 0.639621376991272, 0.6396222710609436, 0.46748876571655273, 0.46748876571655273, 0.6257374882698059, 0.6257374882698059, 0.3134478032588959, 0.6268956065177917, 0.3134478032588959, 0.38132941722869873, 0.38132941722869873, 0.38132941722869873, 0.7604221105575562, 0.49905163049697876, 0.24952581524848938, 0.12476290762424469, 0.12476290762424469, 0.9378384947776794, 0.38382411003112793, 0.7676482200622559, 0.639621376991272, 0.6257374882698059, 0.9631717801094055, 0.6257374882698059, 0.6257374882698059, 0.9287864565849304, 0.6203609108924866, 0.6257374882698059, 0.6257374882698059, 0.6330426931381226, 0.7548877000808716, 0.3774438500404358, 0.6257374882698059, 0.6257372498512268, 0.6203609108924866, 0.6203609108924866, 0.6330426931381226, 0.4679594933986664, 0.4679594933986664, 0.6257374882698059, 0.31595173478126526, 0.31595173478126526, 0.31595173478126526, 0.6257374882698059, 0.6257374882698059, 0.6203609108924866], \"Term\": [\"100_100_face_mask_blood\", \"100_room_air_100_weight\", \"101_and_respiratory_rates_with\", \"108_oxygen_saturation_liters_nasal\", \"108_pulse_101_and_respiratory\", \"110_oxygen_saturation_room_air\", \"118_140_heart_rate_respiratory\", \"120_respiratory_rate_100_100\", \"124_151_respiratory_rate_oxygen\", \"130_respirations_were_and_sating\", \"130_respiratory_rate_and_oxygen\", \"138_respiratory_rate_sating_room\", \"140_heart_rate_respiratory_rate\", \"150_and_breathing_with_room\", \"150_milligrams_mouth_twice_day\", \"150_respiratory_rate_oxygen_saturation\", \"150_respiratory_rate_oxygen_saturation\", \"151_respiratory_rate_oxygen_saturation\", \"air_and_respiratory_rate_blood\", \"air_and_today_weight_listed\", \"air_blood_pressure_less_than\", \"air_blood_pressure_less_than\", \"air_cardiovascular_regular_rate_and\", \"air_general_appearance_elderly_looking\", \"and_and_examination_was_within\", \"and_breathing_with_room_air\", \"and_examination_was_within_normal\", \"and_oxygen_saturation_room_air\", \"and_oxygen_saturation_room_air\", \"and_oxygen_saturation_room_air\", \"and_regular_blood_pressure_right\", \"and_respiratory_rate_blood_pressure\", \"and_respiratory_rate_blood_pressure\", \"and_respiratory_rate_blood_pressure\", \"and_respiratory_rates_with_saturations\", \"and_saturations_liters_oxygen_with\", \"and_today_weight_listed_kilograms\", \"and_was_saturating_room_air\", \"and_weight_and_call_earl\", \"apparent_distress_with_bilateral_hearing\", \"appearance_elderly_looking_gentleman_apparent\", \"bilateral_rales_two_thirds_the\", \"blood_pressure_108_oxygen_saturation\", \"blood_pressure_108_oxygen_saturation\", \"blood_pressure_108_pulse_101\", \"blood_pressure_110_oxygen_saturation\", \"blood_pressure_110_respiratory_rate\", \"blood_pressure_110_respiratory_rate\", \"blood_pressure_110_respiratory_rate\", \"blood_pressure_110_respiratory_rate\", \"blood_pressure_118_140_heart\", \"blood_pressure_120_respiratory_rate\", \"blood_pressure_130_respiratory_rate\", \"blood_pressure_130_respiratory_rate\", \"blood_pressure_132_respiratory_rate\", \"blood_pressure_132_respiratory_rate\", \"blood_pressure_132_respiratory_rate\", \"blood_pressure_140_pulse_saturation\", \"blood_pressure_140_respiratory_rate\", \"blood_pressure_140_respiratory_rate\", \"blood_pressure_150_and_breathing\", \"blood_pressure_150_respiratory_rate\", \"blood_pressure_150_respiratory_rate\", \"blood_pressure_150_respiratory_rate\", \"blood_pressure_160_respiratory_rate\", \"blood_pressure_160_respiratory_rate\", \"blood_pressure_and_heart_rate\", \"blood_pressure_and_heart_rate\", \"blood_pressure_and_weight_and\", \"blood_pressure_control_blood_pressure\", \"blood_pressure_control_blood_pressure\", \"blood_pressure_control_blood_pressure\", \"blood_pressure_control_blood_pressure\", \"blood_pressure_less_than_100\", \"blood_pressure_less_than_100\", \"blood_pressure_less_than_100\", \"blood_pressure_less_than_100\", \"blood_pressure_respiratory_rate_oxygen\", \"blood_pressure_room_air_sat\", \"blood_pressure_the_left_arm\", \"blood_pressure_the_left_arm\", \"blood_pressure_the_left_arm\", \"blood_pressure_the_right_arm\", \"blood_pressure_the_right_arm\", \"blood_pressure_the_right_arm\", \"blood_pressure_was_130_respirations\", \"breathing_times_minute_and_satting\", \"breathing_with_room_air_saturation\", \"cardiovascular_regular_rate_and_rhythm\", \"cardiovascular_regular_rate_and_rhythm\", \"chest_showed_bilateral_rales_two\", \"condition_stable_plan_dictated_summary\", \"condition_stable_plan_dictated_summary\", \"condition_stable_plan_dictated_summary\", \"discharge_condition_stable_plan_dictated\", \"discharge_condition_stable_plan_dictated\", \"discharge_condition_stable_plan_dictated\", \"distress_with_bilateral_hearing_aids\", \"drain_remains_place_draining_fluid\", \"draining_fluid_yesterday_and_the\", \"elderly_looking_gentleman_apparent_distress\", \"equal_round_and_reactive_light\", \"equal_round_and_reactive_light\", \"equal_round_and_reactive_light\", \"equal_round_and_reactive_light\", \"examination_revealed_jugular_venous_pressure\", \"examination_was_within_normal_limits\", \"flap_drain_remains_place_draining\", \"fluid_yesterday_and_the_time\", \"general_appearance_elderly_looking_gentleman\", \"gentleman_apparent_distress_with_bilateral\", \"give_units_subcutaneously_blood_sugar\", \"heart_rate_and_regular_blood\", \"heart_rate_respiratory_rate_oxygen\", \"heent_examination_revealed_jugular_venous\", \"jugular_venous_pressure_chest_showed\", \"kilograms_flap_drain_remains_place\", \"kilograms_note_preoperative_weight_listed\", \"listed_kilograms_flap_drain_remains\", \"listed_kilograms_note_preoperative_weight\", \"liters_heent_examination_revealed_jugular\", \"liters_nasal_cannula_blood_pressure\", \"liters_nasal_cannula_blood_pressure\", \"liters_nasal_cannula_blood_pressure\", \"liters_nasal_cannula_blood_pressure\", \"looking_gentleman_apparent_distress_with\", \"minute_and_satting_100_nonrebreather\", \"mouth_every_hours_needed_for\", \"note_preoperative_weight_listed_kilograms\", \"oxygen_saturation_100_room_air\", \"oxygen_saturation_100_room_air\", \"oxygen_saturation_liters_nasal_cannula\", \"oxygen_saturation_liters_nasal_cannula\", \"oxygen_saturation_liters_nasal_cannula\", \"oxygen_saturation_liters_nasal_cannula\", \"oxygen_saturation_room_air_and\", \"oxygen_saturation_room_air_and\", \"oxygen_saturation_room_air_blood\", \"oxygen_saturation_room_air_blood\", \"oxygen_saturation_room_air_cardiovascular\", \"oxygen_saturation_room_air_general\", \"oxygen_saturation_room_air_general\", \"oxygen_saturation_was_room_air\", \"oxygen_saturation_was_room_air\", \"place_draining_fluid_yesterday_and\", \"preoperative_weight_listed_kilograms_flap\", \"pressure_108_oxygen_saturation_liters\", \"pressure_108_pulse_101_and\", \"pressure_110_oxygen_saturation_room\", \"pressure_110_respiratory_rate_and\", \"pressure_110_respiratory_rate_and\", \"pressure_110_respiratory_rate_and\", \"pressure_115_respiratory_rate_and\", \"pressure_118_140_heart_rate\", \"pressure_120_respiratory_rate_100\", \"pressure_138_respiratory_rate_sating\", \"pressure_140_pulse_saturation_room\", \"pressure_150_and_breathing_with\", \"pressure_150_respiratory_rate_oxygen\", \"pressure_150_respiratory_rate_oxygen\", \"pressure_and_weight_and_call\", \"pressure_chest_showed_bilateral_rales\", \"pressure_less_than_100_heart\", \"pressure_less_than_100_heart\", \"pressure_respiratory_rate_oxygen_saturation\", \"pressure_room_air_sat_was\", \"pressure_the_right_arm_140\", \"pressure_the_right_arm_140\", \"pressure_was_130_respirations_were\", \"pulse_101_and_respiratory_rates\", \"pulse_saturation_room_air_and\", \"rales_two_thirds_the_way\", \"rate_100_100_face_mask\", \"rate_and_oxygen_saturation_100\", \"rate_and_oxygen_saturation_room\", \"rate_and_oxygen_saturation_room\", \"rate_and_regular_blood_pressure\", \"rate_and_saturation_room_air\", \"rate_and_saturations_liters_oxygen\", \"rate_oxygen_saturation_100_room\", \"rate_oxygen_saturation_room_air\", \"rate_oxygen_saturation_room_air\", \"rate_oxygen_saturation_room_air\", \"rate_respiratory_rate_oxygen_saturation\", \"rate_saturation_room_air_blood\", \"rate_saturation_room_air_blood\", \"rate_saturation_room_air_blood\", \"rate_saturation_room_air_blood\", \"rate_with_room_air_saturation\", \"rate_with_room_air_saturation\", \"rates_with_saturations_three_liters\", \"regular_blood_pressure_right_arm\", \"regular_rate_and_rhythm_with\", \"regular_rate_and_rhythm_with\", \"remains_place_draining_fluid_yesterday\", \"respirations_were_and_sating_room\", \"respiratory_rate_100_100_face\", \"respiratory_rate_and_oxygen_saturation\", \"respiratory_rate_and_oxygen_saturation\", \"respiratory_rate_and_saturating_liters\", \"respiratory_rate_and_saturation_liters\", \"respiratory_rate_and_saturation_liters\", \"respiratory_rate_and_saturation_room\", \"respiratory_rate_and_saturations_liters\", \"respiratory_rate_oxygen_saturation_100\", \"respiratory_rate_oxygen_saturation_liters\", \"respiratory_rate_oxygen_saturation_room\", \"respiratory_rate_oxygen_saturation_room\", \"respiratory_rate_oxygen_saturation_room\", \"respiratory_rate_sat_room_air\", \"respiratory_rate_sat_room_air\", \"respiratory_rate_sating_room_air\", \"respiratory_rate_satting_room_air\", \"respiratory_rate_satting_room_air\", \"respiratory_rate_saturation_room_air\", \"respiratory_rate_saturation_room_air\", \"respiratory_rate_saturation_room_air\", \"respiratory_rate_saturation_room_air\", \"respiratory_rate_with_room_air\", \"respiratory_rate_with_room_air\", \"respiratory_rates_with_saturations_three\", \"revealed_jugular_venous_pressure_chest\", \"room_air_and_respiratory_rate\", \"room_air_and_today_weight\", \"room_air_blood_pressure_and\", \"room_air_blood_pressure_and\", \"room_air_blood_pressure_less\", \"room_air_blood_pressure_less\", \"room_air_blood_pressure_was\", \"room_air_blood_pressure_was\", \"room_air_blood_pressure_was\", \"room_air_cardiovascular_regular_rate\", \"room_air_general_appearance_elderly\", \"room_air_saturation_blood_pressure\", \"room_air_saturation_blood_pressure\", \"room_air_saturation_blood_pressure\", \"sating_room_air_blood_pressure\", \"satting_room_air_blood_pressure\", \"satting_room_air_blood_pressure\", \"satting_room_air_blood_pressure\", \"saturating_room_air_blood_pressure\", \"saturating_room_air_blood_pressure\", \"saturation_100_room_air_100\", \"saturation_liters_nasal_cannula_blood\", \"saturation_liters_nasal_cannula_blood\", \"saturation_liters_nasal_cannula_blood\", \"saturation_liters_nasal_cannula_blood\", \"saturation_room_air_and_respiratory\", \"saturation_room_air_and_today\", \"saturation_room_air_blood_pressure\", \"saturation_room_air_blood_pressure\", \"saturation_room_air_blood_pressure\", \"saturation_room_air_blood_pressure\", \"saturation_room_air_cardiovascular_regular\", \"saturation_room_air_general_appearance\", \"saturations_and_and_examination_was\", \"saturations_liters_oxygen_with_liters\", \"saturations_room_air_blood_pressure\", \"saturations_room_air_blood_pressure\", \"saturations_three_liters_heent_examination\", \"showed_bilateral_rales_two_thirds\", \"stable_plan_dictated_summary_entered\", \"stable_plan_dictated_summary_entered\", \"stable_plan_dictated_summary_entered\", \"systolic_blood_pressure_less_than\", \"systolic_blood_pressure_less_than\", \"systolic_blood_pressure_less_than\", \"temperature_heart_rate_and_regular\", \"temperature_heart_rate_blood_pressure\", \"temperature_heart_rate_blood_pressure\", \"temperature_heart_rate_blood_pressure\", \"temperature_heart_rate_blood_pressure\", \"temperature_heart_rate_respiratory_rate\", \"temperature_pulse_blood_pressure_140\", \"temperature_pulse_blood_pressure_140\", \"temperature_saturations_and_and_examination\", \"the_way_without_wheezes_and\", \"then_give_units_subcutaneously_blood\", \"thirds_the_way_without_wheezes\", \"three_liters_heent_examination_revealed\", \"times_minute_and_satting_100\", \"today_weight_listed_kilograms_note\", \"two_thirds_the_way_without\", \"venous_pressure_chest_showed_bilateral\", \"was_130_respirations_were_and\", \"was_saturating_room_air_blood\", \"was_saturating_room_air_blood\", \"way_without_wheezes_and_focal\", \"weight_and_call_earl_frankiewicz\", \"weight_listed_kilograms_flap_drain\", \"weight_listed_kilograms_note_preoperative\", \"were_and_sating_room_air\", \"were_equal_round_and_reactive\", \"were_equal_round_and_reactive\", \"wheezes_and_focal_findings_egophony\", \"with_room_air_saturation_blood\", \"with_room_air_saturation_blood\", \"with_room_air_saturation_blood\", \"with_saturations_three_liters_heent\", \"without_wheezes_and_focal_findings\", \"yesterday_and_the_time_discharge\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 2, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el471331399873812824005099018531\", ldavis_el471331399873812824005099018531_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el471331399873812824005099018531\", ldavis_el471331399873812824005099018531_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el471331399873812824005099018531\", ldavis_el471331399873812824005099018531_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2      0.091185  0.054681       1        1  26.132710\n",
       "0     -0.105698  0.043279       2        1  25.457747\n",
       "1      0.005069 -0.117372       3        1  24.631176\n",
       "3      0.009444  0.019412       4        1  23.778366, topic_info=     Category      Freq                                           Term  \\\n",
       "term                                                                     \n",
       "4719  Default  3.000000          give_units_subcutaneously_blood_sugar   \n",
       "3806  Default  3.000000     saturation_room_air_cardiovascular_regular   \n",
       "3805  Default  3.000000           room_air_cardiovascular_regular_rate   \n",
       "3775  Default  3.000000            air_cardiovascular_regular_rate_and   \n",
       "996   Default  4.000000         respiratory_rate_and_oxygen_saturation   \n",
       "3802  Default  4.000000                   regular_rate_and_rhythm_with   \n",
       "2224  Default  4.000000         cardiovascular_regular_rate_and_rhythm   \n",
       "4804  Default  3.000000           then_give_units_subcutaneously_blood   \n",
       "2149  Default  3.000000         respiratory_rate_oxygen_saturation_100   \n",
       "298   Default  5.000000               oxygen_saturation_room_air_blood   \n",
       "2050  Default  4.000000            blood_pressure_130_respiratory_rate   \n",
       "926   Default  4.000000            blood_pressure_140_respiratory_rate   \n",
       "5284  Default  2.000000                rate_oxygen_saturation_100_room   \n",
       "3797  Default  2.000000      oxygen_saturation_room_air_cardiovascular   \n",
       "3789  Default  2.000000                   heart_rate_and_regular_blood   \n",
       "3799  Default  2.000000                rate_and_regular_blood_pressure   \n",
       "3801  Default  2.000000               regular_blood_pressure_right_arm   \n",
       "3808  Default  2.000000             temperature_heart_rate_and_regular   \n",
       "3778  Default  2.000000               and_regular_blood_pressure_right   \n",
       "228   Default  7.000000        respiratory_rate_oxygen_saturation_room   \n",
       "227   Default  7.000000                rate_oxygen_saturation_room_air   \n",
       "2669  Default  2.000000            blood_pressure_120_respiratory_rate   \n",
       "2054  Default  3.000000                 oxygen_saturation_100_room_air   \n",
       "855   Default  3.000000                  blood_pressure_and_heart_rate   \n",
       "170   Default  6.000000                   blood_pressure_the_right_arm   \n",
       "296   Default  8.000000                   blood_pressure_less_than_100   \n",
       "5269  Default  3.000000            blood_pressure_160_respiratory_rate   \n",
       "869   Default  2.000000         respiratory_rate_and_saturating_liters   \n",
       "3279  Default  2.000000                   mouth_every_hours_needed_for   \n",
       "1341  Default  2.000000             breathing_with_room_air_saturation   \n",
       "...       ...       ...                                            ...   \n",
       "5937   Topic4  1.163156         air_general_appearance_elderly_looking   \n",
       "5939   Topic4  1.163156  appearance_elderly_looking_gentleman_apparent   \n",
       "5938   Topic4  1.163156       apparent_distress_with_bilateral_hearing   \n",
       "2054   Topic4  2.198228                 oxygen_saturation_100_room_air   \n",
       "855    Topic4  2.197276                  blood_pressure_and_heart_rate   \n",
       "2050   Topic4  2.717641            blood_pressure_130_respiratory_rate   \n",
       "926    Topic4  2.714675            blood_pressure_140_respiratory_rate   \n",
       "531    Topic4  1.682347           temperature_pulse_blood_pressure_140   \n",
       "1162   Topic4  1.680294                   pressure_less_than_100_heart   \n",
       "633    Topic4  2.199095            liters_nasal_cannula_blood_pressure   \n",
       "296    Topic4  2.724993                   blood_pressure_less_than_100   \n",
       "323    Topic4  1.163155              pressure_115_respiratory_rate_and   \n",
       "325    Topic4  1.163155             rate_and_saturations_liters_oxygen   \n",
       "327    Topic4  1.163155        respiratory_rate_and_saturations_liters   \n",
       "328    Topic4  1.163155          saturations_liters_oxygen_with_liters   \n",
       "1106   Topic4  1.682715            and_respiratory_rate_blood_pressure   \n",
       "308    Topic4  1.163155             and_saturations_liters_oxygen_with   \n",
       "227    Topic4  1.683123                rate_oxygen_saturation_room_air   \n",
       "228    Topic4  1.683123        respiratory_rate_oxygen_saturation_room   \n",
       "355    Topic4  1.166067                 equal_round_and_reactive_light   \n",
       "631    Topic4  1.165504            blood_pressure_150_respiratory_rate   \n",
       "833    Topic4  1.164749                 rate_saturation_room_air_blood   \n",
       "640    Topic4  1.164331          saturation_liters_nasal_cannula_blood   \n",
       "835    Topic4  1.164154           respiratory_rate_saturation_room_air   \n",
       "636    Topic4  1.163885           pressure_150_respiratory_rate_oxygen   \n",
       "630    Topic4  1.163885         150_respiratory_rate_oxygen_saturation   \n",
       "19     Topic4  1.163815          blood_pressure_control_blood_pressure   \n",
       "1665   Topic4  1.163711              systolic_blood_pressure_less_than   \n",
       "966    Topic4  1.163700             oxygen_saturation_room_air_general   \n",
       "635    Topic4  1.163517         oxygen_saturation_liters_nasal_cannula   \n",
       "\n",
       "         Total  loglift  logprob  \n",
       "term                              \n",
       "4719  3.000000  30.0000  30.0000  \n",
       "3806  3.000000  29.0000  29.0000  \n",
       "3805  3.000000  28.0000  28.0000  \n",
       "3775  3.000000  27.0000  27.0000  \n",
       "996   4.000000  26.0000  26.0000  \n",
       "3802  4.000000  25.0000  25.0000  \n",
       "2224  4.000000  24.0000  24.0000  \n",
       "4804  3.000000  23.0000  23.0000  \n",
       "2149  3.000000  22.0000  22.0000  \n",
       "298   5.000000  21.0000  21.0000  \n",
       "2050  4.000000  20.0000  20.0000  \n",
       "926   4.000000  19.0000  19.0000  \n",
       "5284  2.000000  18.0000  18.0000  \n",
       "3797  2.000000  17.0000  17.0000  \n",
       "3789  2.000000  16.0000  16.0000  \n",
       "3799  2.000000  15.0000  15.0000  \n",
       "3801  2.000000  14.0000  14.0000  \n",
       "3808  2.000000  13.0000  13.0000  \n",
       "3778  2.000000  12.0000  12.0000  \n",
       "228   7.000000  11.0000  11.0000  \n",
       "227   7.000000  10.0000  10.0000  \n",
       "2669  2.000000   9.0000   9.0000  \n",
       "2054  3.000000   8.0000   8.0000  \n",
       "855   3.000000   7.0000   7.0000  \n",
       "170   6.000000   6.0000   6.0000  \n",
       "296   8.000000   5.0000   5.0000  \n",
       "5269  3.000000   4.0000   4.0000  \n",
       "869   2.000000   3.0000   3.0000  \n",
       "3279  2.000000   2.0000   2.0000  \n",
       "1341  2.000000   1.0000   1.0000  \n",
       "...        ...      ...      ...  \n",
       "5937  1.563423   1.1407  -7.4789  \n",
       "5939  1.563423   1.1407  -7.4789  \n",
       "5938  1.563423   1.1407  -7.4789  \n",
       "2054  3.138600   1.0803  -6.8424  \n",
       "855   3.138636   1.0798  -6.8429  \n",
       "2050  4.196907   1.0018  -6.6303  \n",
       "926   4.197122   1.0007  -6.6314  \n",
       "531   2.605360   0.9990  -7.1099  \n",
       "1162  2.621542   0.9916  -7.1111  \n",
       "633   5.273439   0.5618  -6.8420  \n",
       "296   8.400344   0.3106  -6.6276  \n",
       "323   1.563423   1.1407  -7.4789  \n",
       "325   1.563423   1.1407  -7.4789  \n",
       "327   1.563423   1.1407  -7.4789  \n",
       "328   1.563423   1.1407  -7.4789  \n",
       "1106  4.770674   0.3943  -7.1097  \n",
       "308   1.563423   1.1407  -7.4789  \n",
       "227   7.445254  -0.0505  -7.1094  \n",
       "228   7.445254  -0.0505  -7.1094  \n",
       "355   4.246378   0.1440  -7.4764  \n",
       "631   3.170702   0.4356  -7.4769  \n",
       "833   3.163403   0.4373  -7.4776  \n",
       "640   3.163363   0.4369  -7.4779  \n",
       "835   4.230080   0.1462  -7.4781  \n",
       "636   2.645814   0.6152  -7.4783  \n",
       "630   2.645814   0.6152  -7.4783  \n",
       "19    3.697918   0.2803  -7.4784  \n",
       "1665  2.622405   0.6239  -7.4785  \n",
       "966   2.104420   0.8440  -7.4785  \n",
       "635   4.230032   0.1456  -7.4786  \n",
       "\n",
       "[248 rows x 6 columns], token_table=      Topic      Freq                                         Term\n",
       "term                                                              \n",
       "4274      1  0.620361                      100_100_face_mask_blood\n",
       "5258      4  0.639622                      100_room_air_100_weight\n",
       "6905      2  0.625737               101_and_respiratory_rates_with\n",
       "3190      3  0.633042           108_oxygen_saturation_liters_nasal\n",
       "6906      2  0.625737                108_pulse_101_and_respiratory\n",
       "5069      1  0.620361               110_oxygen_saturation_room_air\n",
       "5260      4  0.639622               118_140_heart_rate_respiratory\n",
       "4280      1  0.620361                 120_respiratory_rate_100_100\n",
       "5517      1  0.620361              124_151_respiratory_rate_oxygen\n",
       "7004      3  0.633043             130_respirations_were_and_sating\n",
       "2044      1  0.928787              130_respiratory_rate_and_oxygen\n",
       "7005      3  0.633043             138_respiratory_rate_sating_room\n",
       "5261      4  0.639622              140_heart_rate_respiratory_rate\n",
       "1319      3  0.633042                  150_and_breathing_with_room\n",
       "3192      3  0.633042               150_milligrams_mouth_twice_day\n",
       "630       1  0.377956       150_respiratory_rate_oxygen_saturation\n",
       "630       4  0.377956       150_respiratory_rate_oxygen_saturation\n",
       "5518      1  0.620361       151_respiratory_rate_oxygen_saturation\n",
       "3517      1  0.928788               air_and_respiratory_rate_blood\n",
       "5070      1  0.620361                  air_and_today_weight_listed\n",
       "294       2  0.378932                 air_blood_pressure_less_than\n",
       "294       3  0.757864                 air_blood_pressure_less_than\n",
       "3775      3  0.815094          air_cardiovascular_regular_rate_and\n",
       "5937      4  0.639622       air_general_appearance_elderly_looking\n",
       "1443      4  0.639621               and_and_examination_was_within\n",
       "1326      3  0.633042                  and_breathing_with_room_air\n",
       "1445      4  0.639621            and_examination_was_within_normal\n",
       "578       1  0.469197               and_oxygen_saturation_room_air\n",
       "578       2  0.234599               and_oxygen_saturation_room_air\n",
       "578       3  0.469197               and_oxygen_saturation_room_air\n",
       "...     ...       ...                                          ...\n",
       "373       4  0.124763        temperature_heart_rate_blood_pressure\n",
       "905       2  0.937838      temperature_heart_rate_respiratory_rate\n",
       "531       3  0.383824         temperature_pulse_blood_pressure_140\n",
       "531       4  0.767648         temperature_pulse_blood_pressure_140\n",
       "1491      4  0.639621  temperature_saturations_and_and_examination\n",
       "6962      2  0.625737                  the_way_without_wheezes_and\n",
       "4804      4  0.963172         then_give_units_subcutaneously_blood\n",
       "6964      2  0.625737               thirds_the_way_without_wheezes\n",
       "6965      2  0.625737      three_liters_heent_examination_revealed\n",
       "5735      1  0.928786                 times_minute_and_satting_100\n",
       "5119      1  0.620361           today_weight_listed_kilograms_note\n",
       "6966      2  0.625737                   two_thirds_the_way_without\n",
       "6967      2  0.625737       venous_pressure_chest_showed_bilateral\n",
       "7053      3  0.633043                was_130_respirations_were_and\n",
       "3497      2  0.754888                was_saturating_room_air_blood\n",
       "3497      4  0.377444                was_saturating_room_air_blood\n",
       "6969      2  0.625737                way_without_wheezes_and_focal\n",
       "6671      2  0.625737             weight_and_call_earl_frankiewicz\n",
       "5120      1  0.620361           weight_listed_kilograms_flap_drain\n",
       "5121      1  0.620361    weight_listed_kilograms_note_preoperative\n",
       "7054      3  0.633043                     were_and_sating_room_air\n",
       "376       1  0.467959                were_equal_round_and_reactive\n",
       "376       3  0.467959                were_equal_round_and_reactive\n",
       "6971      2  0.625737          wheezes_and_focal_findings_egophony\n",
       "1397      2  0.315952               with_room_air_saturation_blood\n",
       "1397      3  0.315952               with_room_air_saturation_blood\n",
       "1397      4  0.315952               with_room_air_saturation_blood\n",
       "6973      2  0.625737          with_saturations_three_liters_heent\n",
       "6974      2  0.625737           without_wheezes_and_focal_findings\n",
       "5123      1  0.620361             yesterday_and_the_time_discharge\n",
       "\n",
       "[301 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 1, 2, 4])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "visualize results\n",
    "\"\"\"\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Visualize the topics\n",
    "id2word=dictionary\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering-derived: use LDA on medications tokens\n",
    "create dictionary and corpus and save for future use\n",
    "\"\"\"\n",
    "start=time.time()\n",
    "dictionary = gensim.corpora.Dictionary(meds_tokens)\n",
    "\n",
    "#create corpus \n",
    "corpus = [dictionary.doc2bow(text) for text in meds_tokens]\n",
    "#save corpus and dictionary\n",
    "pickle.dump(corpus, open('i2b2-corpus.pkl', 'wb'))\n",
    "dictionary.save('i2b2-medications.gensim')\n",
    "end=time.time()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature engineering-derived: use LDA on full text\n",
    "create dictionary and corpus and save for future use\n",
    "\"\"\"\n",
    "dictionary = gensim.corpora.Dictionary(text_tokens)\n",
    "\n",
    "#create corpus \n",
    "corpus = [dictionary.doc2bow(text) for text in text_tokens]\n",
    "#save corpus and dictionary\n",
    "pickle.dump(corpus, open('i2b2-corpus.pkl', 'wb'))\n",
    "dictionary.save('i2b2-medications.gensim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature-engineering: bi-grams and tri-grams\n",
    "data: df['discharge_medication_context']\n",
    "\"\"\"\n",
    "from nltk import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "#bigrm = list(nltk.bigrams((str(df['discharge_medication_context']).split())))\n",
    "fourgrams=[]\n",
    "for line in df['discharge_medication_context']:\n",
    "    tokens=word_tokenize(str(line))\n",
    "    trigrams=ngrams(tokens,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['discharge_medication_context_bigrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "###EXPERIMENTAL\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding diagnosis related content by using similarity matching\n",
    "need to try Facebook Research's GPU accelerated library:https://github.com/facebookresearch/faiss\n",
    "https://github.com/facebookresearch/faiss/issues/54\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "from fuzzywuzzy import fuzz\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame()\n",
    "start=time.time()\n",
    "lines=[]\n",
    "matches=[]\n",
    "diagnosis_list=[]\n",
    "text=[]\n",
    "diagnosis_list.append(sent_tokenize(str(dx_list)))\n",
    "matches_list=[]\n",
    "text_list=[]\n",
    "for row in df['text']:\n",
    "    matches=[]\n",
    "    sentences=[]\n",
    "    lines.append(sent_tokenize(str(row)))\n",
    "    \n",
    "    for line in lines:\n",
    "        sentences.append(sent_tokenize(str(line)))\n",
    "        for sentence in sentences:\n",
    "            for a in sentence:\n",
    "                a=re.sub(r'([^\\s\\w]|_)+', '', str(a))\n",
    "                a=result = ''.join([i for i in a if not i.isdigit()])\n",
    "                for n in dx_list:              \n",
    "                   \n",
    "                    #base,blank,modifier=str(n).partition(\" \")\n",
    "                    \n",
    "                    b=re.sub(r'([^\\s\\w]|_)+', '', str(n))\n",
    "                    #if str(b) in str(a):\n",
    "                   \n",
    "                    \n",
    "                    value=fuzz.token_set_ratio(a,b)\n",
    "                    if value>70:\n",
    "                        keep, word,snippet=a.partition(str(b))\n",
    "                        matches.append(b)\n",
    "                        text.append(a)\n",
    "                        continue\n",
    "                    else:\n",
    "                        #matches.append(\"none\")\n",
    "                        continue\n",
    "            continue\n",
    "        continue\n",
    "    \n",
    "    matches_list.extend(matches)\n",
    "    text_list.extend(text)\n",
    "    continue\n",
    "end=time.time()\n",
    "print(\"all records processed\") \n",
    "print(\"time to process:\",(end-start))\n",
    "list(set(matches))\n",
    "df1['diagnostic']=matches\n",
    "df1['text']=text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Read in Diagnosis file \n",
    "#take only first word\"\n",
    "dx=pd.read_csv(r\"/rapids/notebooks/hostfs/dx.txt\",sep=\"\\t\",error_bad_lines=False)\n",
    "dx_list=dx.values.tolist()\n",
    "single_dx_list=[]\n",
    "for i in dx_list:\n",
    "    i=str(i).split()[0].lower()\n",
    "    single_dx_list.append(i)\n",
    "list(set(single_dx_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
